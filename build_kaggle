{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":30892,"databundleVersionId":2715462,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:43:44.643978Z","iopub.execute_input":"2024-11-23T13:43:44.644567Z","iopub.status.idle":"2024-11-23T13:43:45.762621Z","shell.execute_reply.started":"2024-11-23T13:43:44.644535Z","shell.execute_reply":"2024-11-23T13:43:45.761607Z"}},"outputs":[{"name":"stdout","text":"Sat Nov 23 13:43:45 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   42C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   37C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install torchsummary\n!pip install torchgeometry","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:43:48.203419Z","iopub.execute_input":"2024-11-23T13:43:48.204317Z","iopub.status.idle":"2024-11-23T13:44:06.962061Z","shell.execute_reply.started":"2024-11-23T13:43:48.204280Z","shell.execute_reply":"2024-11-23T13:44:06.961203Z"}},"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\nCollecting torchgeometry\n  Downloading torchgeometry-0.1.2-py2.py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torchgeometry) (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->torchgeometry) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->torchgeometry) (1.3.0)\nDownloading torchgeometry-0.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torchgeometry\nSuccessfully installed torchgeometry-0.1.2\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install segmentation-models-pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:44:41.558522Z","iopub.execute_input":"2024-11-23T13:44:41.558888Z","iopub.status.idle":"2024-11-23T13:44:55.537321Z","shell.execute_reply.started":"2024-11-23T13:44:41.558854Z","shell.execute_reply":"2024-11-23T13:44:55.536234Z"}},"outputs":[{"name":"stdout","text":"Collecting segmentation-models-pytorch\n  Downloading segmentation_models_pytorch-0.3.4-py3-none-any.whl.metadata (30 kB)\nCollecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: huggingface-hub>=0.24.6 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.25.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.3.0)\nCollecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (1.16.0)\nCollecting timm==0.9.7 (from segmentation-models-pytorch)\n  Downloading timm-0.9.7-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.19.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.4.0)\nCollecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (4.12.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\nDownloading segmentation_models_pytorch-0.3.4-py3-none-any.whl (109 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=306a33deac3981a01de91e0afac3dbd9de42abcdd5650d8831faf6e11e7f0c05\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=eb283b1b9d01c36bdd75e1ae42572b60adbb0e8a1a0abf22d243716f60d72ecf\n  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\nSuccessfully built efficientnet-pytorch pretrainedmodels\nInstalling collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.9\n    Uninstalling timm-1.0.9:\n      Successfully uninstalled timm-1.0.9\nSuccessfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.4 timm-0.9.7\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport segmentation_models_pytorch as smp\n\nimport cv2\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport time\nfrom PIL import Image\nimport os\n\nimport wandb\nfrom torchsummary import summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:44:55.539557Z","iopub.execute_input":"2024-11-23T13:44:55.540329Z","iopub.status.idle":"2024-11-23T13:44:58.358391Z","shell.execute_reply.started":"2024-11-23T13:44:55.540281Z","shell.execute_reply":"2024-11-23T13:44:58.357472Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 6","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:45:03.380295Z","iopub.execute_input":"2024-11-23T13:45:03.380928Z","iopub.status.idle":"2024-11-23T13:45:03.384343Z","shell.execute_reply.started":"2024-11-23T13:45:03.380896Z","shell.execute_reply":"2024-11-23T13:45:03.383533Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"IMAGES_PATH = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\nMASKS_PATH =  \"/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt/\"\nTEST_PATH = \"/kaggle/input/bkai-igh-neopolyp/test/test/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:45:05.417027Z","iopub.execute_input":"2024-11-23T13:45:05.417810Z","iopub.status.idle":"2024-11-23T13:45:05.421521Z","shell.execute_reply.started":"2024-11-23T13:45:05.417773Z","shell.execute_reply":"2024-11-23T13:45:05.420714Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### transform","metadata":{}},{"cell_type":"code","source":"#transf with ImageNet statistics\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:45:10.558375Z","iopub.execute_input":"2024-11-23T13:45:10.558761Z","iopub.status.idle":"2024-11-23T13:45:10.563757Z","shell.execute_reply.started":"2024-11-23T13:45:10.558729Z","shell.execute_reply":"2024-11-23T13:45:10.562851Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"transform_2 = A.Compose([\n    A.Resize(height=256, width=256),\n    A.HorizontalFlip(p=0.4),\n    A.VerticalFlip(p=0.4),\n    A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:45:15.163149Z","iopub.execute_input":"2024-11-23T13:45:15.163556Z","iopub.status.idle":"2024-11-23T13:45:15.171760Z","shell.execute_reply.started":"2024-11-23T13:45:15.163526Z","shell.execute_reply":"2024-11-23T13:45:15.170806Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2111000807.py:5: UserWarning: Argument 'eps' is not valid and will be ignored.\n  A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### Data","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, image_paths, mask_paths, resize = (256,256), transform=None, color_map=None):\n        self.image_paths = image_paths\n        self.mask_paths = mask_paths\n        self.resize = resize\n        self.transform = transform\n        self.color_map = color_map or {\n            (255, 0, 0): 1,  # Red (neoplastic polyps)\n            (0, 255, 0): 2   # Green (non-neoplastic polyps)\n        }\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def encode_mask(self, mask):\n        \"\"\"\n        Encode RGB mask into single-channel class labels.\n        \"\"\"\n        encoded_mask = np.zeros(mask.shape[:2], dtype=np.uint8)\n        for color, label in self.color_map.items():\n            condition = (mask[:, :, 0] == color[0]) & (mask[:, :, 1] == color[1]) & (mask[:, :, 2] == color[2])\n            encoded_mask[condition] = label\n        return encoded_mask\n\n    def __getitem__(self, idx):\n\n        img_path = self.image_paths[idx]\n        mask_path = self.mask_paths[idx]\n\n        image = cv2.imread(img_path)\n        if image is None:\n            raise FileNotFoundError(f\"Mask not found at {img_path}\")\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        mask = cv2.imread(mask_path)\n        if mask is None:\n            raise FileNotFoundError(f\"Mask not found at {mask_path}\")\n        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n        mask = self.encode_mask(mask)\n\n        if self.transform:\n            transformed = self.transform(image=image, mask=mask)\n            image = transformed['image']\n            mask = transformed['mask']\n   \n        return image, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:45:42.755240Z","iopub.execute_input":"2024-11-23T13:45:42.755804Z","iopub.status.idle":"2024-11-23T13:45:42.763949Z","shell.execute_reply.started":"2024-11-23T13:45:42.755771Z","shell.execute_reply":"2024-11-23T13:45:42.762988Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"image_paths = []\nfor root, dirs, files in os.walk(IMAGES_PATH):\n    for file in files:\n        path = os.path.join(root,file)\n        image_paths.append(path)\n        \nlen(image_paths)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:45:46.633953Z","iopub.execute_input":"2024-11-23T13:45:46.634792Z","iopub.status.idle":"2024-11-23T13:45:47.481860Z","shell.execute_reply.started":"2024-11-23T13:45:46.634755Z","shell.execute_reply":"2024-11-23T13:45:47.481018Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"mask_paths = []\nfor root, dirs, files in os.walk(MASKS_PATH):\n    for file in files:\n        path = os.path.join(root,file)\n        mask_paths.append(path)\n        \nlen(mask_paths)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:45:49.041090Z","iopub.execute_input":"2024-11-23T13:45:49.041430Z","iopub.status.idle":"2024-11-23T13:45:49.936405Z","shell.execute_reply.started":"2024-11-23T13:45:49.041403Z","shell.execute_reply":"2024-11-23T13:45:49.935536Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"init_dataset = CustomDataset(image_paths, mask_paths, transform = transform_2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:45:51.788356Z","iopub.execute_input":"2024-11-23T13:45:51.789098Z","iopub.status.idle":"2024-11-23T13:45:51.792543Z","shell.execute_reply.started":"2024-11-23T13:45:51.789066Z","shell.execute_reply":"2024-11-23T13:45:51.791721Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"print(len(init_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:45:53.967475Z","iopub.execute_input":"2024-11-23T13:45:53.968248Z","iopub.status.idle":"2024-11-23T13:45:53.972303Z","shell.execute_reply.started":"2024-11-23T13:45:53.968207Z","shell.execute_reply":"2024-11-23T13:45:53.971450Z"}},"outputs":[{"name":"stdout","text":"1000\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"train_size = int(len(init_dataset) * 0.80)\nvalid_size = len(init_dataset) - train_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:45:56.331595Z","iopub.execute_input":"2024-11-23T13:45:56.331924Z","iopub.status.idle":"2024-11-23T13:45:56.336081Z","shell.execute_reply.started":"2024-11-23T13:45:56.331896Z","shell.execute_reply":"2024-11-23T13:45:56.335203Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:45:58.482957Z","iopub.execute_input":"2024-11-23T13:45:58.483661Z","iopub.status.idle":"2024-11-23T13:45:58.500586Z","shell.execute_reply.started":"2024-11-23T13:45:58.483628Z","shell.execute_reply":"2024-11-23T13:45:58.499774Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f99b450c510>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"train_set, valid_set = random_split(init_dataset, [train_size, valid_size])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:46:01.693951Z","iopub.execute_input":"2024-11-23T13:46:01.694716Z","iopub.status.idle":"2024-11-23T13:46:01.698722Z","shell.execute_reply.started":"2024-11-23T13:46:01.694680Z","shell.execute_reply":"2024-11-23T13:46:01.697890Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"### Data Loader","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:46:06.749489Z","iopub.execute_input":"2024-11-23T13:46:06.750174Z","iopub.status.idle":"2024-11-23T13:46:06.754038Z","shell.execute_reply.started":"2024-11-23T13:46:06.750129Z","shell.execute_reply":"2024-11-23T13:46:06.753218Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"print(len(train_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:46:09.658015Z","iopub.execute_input":"2024-11-23T13:46:09.658716Z","iopub.status.idle":"2024-11-23T13:46:09.662975Z","shell.execute_reply.started":"2024-11-23T13:46:09.658682Z","shell.execute_reply":"2024-11-23T13:46:09.662171Z"}},"outputs":[{"name":"stdout","text":"134\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# Hyperparameters","metadata":{}},{"cell_type":"code","source":"NUM_CLASSES = 3\nNUM_EPOCHS = 30\nLEARNING_RATE = 1e-4\n\nModel_PATH = '/kaggle/working/unet-model.pth'\n\nPreTrained_path = \"/kaggle/input/unet-checkpoint/unet-model.pth\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:46:12.470481Z","iopub.execute_input":"2024-11-23T13:46:12.471006Z","iopub.status.idle":"2024-11-23T13:46:12.475762Z","shell.execute_reply.started":"2024-11-23T13:46:12.470967Z","shell.execute_reply":"2024-11-23T13:46:12.474770Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nDEVICE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:46:14.891613Z","iopub.execute_input":"2024-11-23T13:46:14.891944Z","iopub.status.idle":"2024-11-23T13:46:14.944237Z","shell.execute_reply.started":"2024-11-23T13:46:14.891914Z","shell.execute_reply":"2024-11-23T13:46:14.943436Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"UNET = smp.UnetPlusPlus(\n    encoder_name=\"resnet34\",        \n    encoder_weights=\"imagenet\",      \n    in_channels=3, \n    classes= NUM_CLASSES,\n    #activation= 'softmax'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:46:16.690686Z","iopub.execute_input":"2024-11-23T13:46:16.691529Z","iopub.status.idle":"2024-11-23T13:46:17.870664Z","shell.execute_reply.started":"2024-11-23T13:46:16.691494Z","shell.execute_reply":"2024-11-23T13:46:17.869743Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n100%|██████████| 83.3M/83.3M [00:00<00:00, 213MB/s] \n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"model = UNET.to(DEVICE)\nsummary(model, (3, 256, 256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:46:41.219870Z","iopub.execute_input":"2024-11-23T13:46:41.220239Z","iopub.status.idle":"2024-11-23T13:46:42.817517Z","shell.execute_reply.started":"2024-11-23T13:46:41.220207Z","shell.execute_reply":"2024-11-23T13:46:42.816704Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 128, 128]           9,408\n       BatchNorm2d-2         [-1, 64, 128, 128]             128\n              ReLU-3         [-1, 64, 128, 128]               0\n         MaxPool2d-4           [-1, 64, 64, 64]               0\n            Conv2d-5           [-1, 64, 64, 64]          36,864\n       BatchNorm2d-6           [-1, 64, 64, 64]             128\n              ReLU-7           [-1, 64, 64, 64]               0\n            Conv2d-8           [-1, 64, 64, 64]          36,864\n       BatchNorm2d-9           [-1, 64, 64, 64]             128\n             ReLU-10           [-1, 64, 64, 64]               0\n       BasicBlock-11           [-1, 64, 64, 64]               0\n           Conv2d-12           [-1, 64, 64, 64]          36,864\n      BatchNorm2d-13           [-1, 64, 64, 64]             128\n             ReLU-14           [-1, 64, 64, 64]               0\n           Conv2d-15           [-1, 64, 64, 64]          36,864\n      BatchNorm2d-16           [-1, 64, 64, 64]             128\n             ReLU-17           [-1, 64, 64, 64]               0\n       BasicBlock-18           [-1, 64, 64, 64]               0\n           Conv2d-19           [-1, 64, 64, 64]          36,864\n      BatchNorm2d-20           [-1, 64, 64, 64]             128\n             ReLU-21           [-1, 64, 64, 64]               0\n           Conv2d-22           [-1, 64, 64, 64]          36,864\n      BatchNorm2d-23           [-1, 64, 64, 64]             128\n             ReLU-24           [-1, 64, 64, 64]               0\n       BasicBlock-25           [-1, 64, 64, 64]               0\n           Conv2d-26          [-1, 128, 32, 32]          73,728\n      BatchNorm2d-27          [-1, 128, 32, 32]             256\n             ReLU-28          [-1, 128, 32, 32]               0\n           Conv2d-29          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-30          [-1, 128, 32, 32]             256\n           Conv2d-31          [-1, 128, 32, 32]           8,192\n      BatchNorm2d-32          [-1, 128, 32, 32]             256\n             ReLU-33          [-1, 128, 32, 32]               0\n       BasicBlock-34          [-1, 128, 32, 32]               0\n           Conv2d-35          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-36          [-1, 128, 32, 32]             256\n             ReLU-37          [-1, 128, 32, 32]               0\n           Conv2d-38          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-39          [-1, 128, 32, 32]             256\n             ReLU-40          [-1, 128, 32, 32]               0\n       BasicBlock-41          [-1, 128, 32, 32]               0\n           Conv2d-42          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-43          [-1, 128, 32, 32]             256\n             ReLU-44          [-1, 128, 32, 32]               0\n           Conv2d-45          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-46          [-1, 128, 32, 32]             256\n             ReLU-47          [-1, 128, 32, 32]               0\n       BasicBlock-48          [-1, 128, 32, 32]               0\n           Conv2d-49          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-50          [-1, 128, 32, 32]             256\n             ReLU-51          [-1, 128, 32, 32]               0\n           Conv2d-52          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-53          [-1, 128, 32, 32]             256\n             ReLU-54          [-1, 128, 32, 32]               0\n       BasicBlock-55          [-1, 128, 32, 32]               0\n           Conv2d-56          [-1, 256, 16, 16]         294,912\n      BatchNorm2d-57          [-1, 256, 16, 16]             512\n             ReLU-58          [-1, 256, 16, 16]               0\n           Conv2d-59          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-60          [-1, 256, 16, 16]             512\n           Conv2d-61          [-1, 256, 16, 16]          32,768\n      BatchNorm2d-62          [-1, 256, 16, 16]             512\n             ReLU-63          [-1, 256, 16, 16]               0\n       BasicBlock-64          [-1, 256, 16, 16]               0\n           Conv2d-65          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-66          [-1, 256, 16, 16]             512\n             ReLU-67          [-1, 256, 16, 16]               0\n           Conv2d-68          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-69          [-1, 256, 16, 16]             512\n             ReLU-70          [-1, 256, 16, 16]               0\n       BasicBlock-71          [-1, 256, 16, 16]               0\n           Conv2d-72          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-73          [-1, 256, 16, 16]             512\n             ReLU-74          [-1, 256, 16, 16]               0\n           Conv2d-75          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-76          [-1, 256, 16, 16]             512\n             ReLU-77          [-1, 256, 16, 16]               0\n       BasicBlock-78          [-1, 256, 16, 16]               0\n           Conv2d-79          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-80          [-1, 256, 16, 16]             512\n             ReLU-81          [-1, 256, 16, 16]               0\n           Conv2d-82          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-83          [-1, 256, 16, 16]             512\n             ReLU-84          [-1, 256, 16, 16]               0\n       BasicBlock-85          [-1, 256, 16, 16]               0\n           Conv2d-86          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-87          [-1, 256, 16, 16]             512\n             ReLU-88          [-1, 256, 16, 16]               0\n           Conv2d-89          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-90          [-1, 256, 16, 16]             512\n             ReLU-91          [-1, 256, 16, 16]               0\n       BasicBlock-92          [-1, 256, 16, 16]               0\n           Conv2d-93          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-94          [-1, 256, 16, 16]             512\n             ReLU-95          [-1, 256, 16, 16]               0\n           Conv2d-96          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-97          [-1, 256, 16, 16]             512\n             ReLU-98          [-1, 256, 16, 16]               0\n       BasicBlock-99          [-1, 256, 16, 16]               0\n          Conv2d-100            [-1, 512, 8, 8]       1,179,648\n     BatchNorm2d-101            [-1, 512, 8, 8]           1,024\n            ReLU-102            [-1, 512, 8, 8]               0\n          Conv2d-103            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-104            [-1, 512, 8, 8]           1,024\n          Conv2d-105            [-1, 512, 8, 8]         131,072\n     BatchNorm2d-106            [-1, 512, 8, 8]           1,024\n            ReLU-107            [-1, 512, 8, 8]               0\n      BasicBlock-108            [-1, 512, 8, 8]               0\n          Conv2d-109            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-110            [-1, 512, 8, 8]           1,024\n            ReLU-111            [-1, 512, 8, 8]               0\n          Conv2d-112            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-113            [-1, 512, 8, 8]           1,024\n            ReLU-114            [-1, 512, 8, 8]               0\n      BasicBlock-115            [-1, 512, 8, 8]               0\n          Conv2d-116            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-117            [-1, 512, 8, 8]           1,024\n            ReLU-118            [-1, 512, 8, 8]               0\n          Conv2d-119            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-120            [-1, 512, 8, 8]           1,024\n            ReLU-121            [-1, 512, 8, 8]               0\n      BasicBlock-122            [-1, 512, 8, 8]               0\n   ResNetEncoder-123  [[-1, 3, 256, 256], [-1, 64, 128, 128], [-1, 64, 64, 64], [-1, 128, 32, 32], [-1, 256, 16, 16], [-1, 512, 8, 8]]               0\n        Identity-124          [-1, 768, 16, 16]               0\n       Attention-125          [-1, 768, 16, 16]               0\n          Conv2d-126          [-1, 256, 16, 16]       1,769,472\n     BatchNorm2d-127          [-1, 256, 16, 16]             512\n            ReLU-128          [-1, 256, 16, 16]               0\n          Conv2d-129          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-130          [-1, 256, 16, 16]             512\n            ReLU-131          [-1, 256, 16, 16]               0\n        Identity-132          [-1, 256, 16, 16]               0\n       Attention-133          [-1, 256, 16, 16]               0\n    DecoderBlock-134          [-1, 256, 16, 16]               0\n        Identity-135          [-1, 384, 32, 32]               0\n       Attention-136          [-1, 384, 32, 32]               0\n          Conv2d-137          [-1, 128, 32, 32]         442,368\n     BatchNorm2d-138          [-1, 128, 32, 32]             256\n            ReLU-139          [-1, 128, 32, 32]               0\n          Conv2d-140          [-1, 128, 32, 32]         147,456\n     BatchNorm2d-141          [-1, 128, 32, 32]             256\n            ReLU-142          [-1, 128, 32, 32]               0\n        Identity-143          [-1, 128, 32, 32]               0\n       Attention-144          [-1, 128, 32, 32]               0\n    DecoderBlock-145          [-1, 128, 32, 32]               0\n        Identity-146          [-1, 192, 64, 64]               0\n       Attention-147          [-1, 192, 64, 64]               0\n          Conv2d-148           [-1, 64, 64, 64]         110,592\n     BatchNorm2d-149           [-1, 64, 64, 64]             128\n            ReLU-150           [-1, 64, 64, 64]               0\n          Conv2d-151           [-1, 64, 64, 64]          36,864\n     BatchNorm2d-152           [-1, 64, 64, 64]             128\n            ReLU-153           [-1, 64, 64, 64]               0\n        Identity-154           [-1, 64, 64, 64]               0\n       Attention-155           [-1, 64, 64, 64]               0\n    DecoderBlock-156           [-1, 64, 64, 64]               0\n        Identity-157        [-1, 128, 128, 128]               0\n       Attention-158        [-1, 128, 128, 128]               0\n          Conv2d-159         [-1, 64, 128, 128]          73,728\n     BatchNorm2d-160         [-1, 64, 128, 128]             128\n            ReLU-161         [-1, 64, 128, 128]               0\n          Conv2d-162         [-1, 64, 128, 128]          36,864\n     BatchNorm2d-163         [-1, 64, 128, 128]             128\n            ReLU-164         [-1, 64, 128, 128]               0\n        Identity-165         [-1, 64, 128, 128]               0\n       Attention-166         [-1, 64, 128, 128]               0\n    DecoderBlock-167         [-1, 64, 128, 128]               0\n        Identity-168          [-1, 512, 32, 32]               0\n       Attention-169          [-1, 512, 32, 32]               0\n          Conv2d-170          [-1, 128, 32, 32]         589,824\n     BatchNorm2d-171          [-1, 128, 32, 32]             256\n            ReLU-172          [-1, 128, 32, 32]               0\n          Conv2d-173          [-1, 128, 32, 32]         147,456\n     BatchNorm2d-174          [-1, 128, 32, 32]             256\n            ReLU-175          [-1, 128, 32, 32]               0\n        Identity-176          [-1, 128, 32, 32]               0\n       Attention-177          [-1, 128, 32, 32]               0\n    DecoderBlock-178          [-1, 128, 32, 32]               0\n        Identity-179          [-1, 256, 64, 64]               0\n       Attention-180          [-1, 256, 64, 64]               0\n          Conv2d-181           [-1, 64, 64, 64]         147,456\n     BatchNorm2d-182           [-1, 64, 64, 64]             128\n            ReLU-183           [-1, 64, 64, 64]               0\n          Conv2d-184           [-1, 64, 64, 64]          36,864\n     BatchNorm2d-185           [-1, 64, 64, 64]             128\n            ReLU-186           [-1, 64, 64, 64]               0\n        Identity-187           [-1, 64, 64, 64]               0\n       Attention-188           [-1, 64, 64, 64]               0\n    DecoderBlock-189           [-1, 64, 64, 64]               0\n        Identity-190        [-1, 192, 128, 128]               0\n       Attention-191        [-1, 192, 128, 128]               0\n          Conv2d-192         [-1, 64, 128, 128]         110,592\n     BatchNorm2d-193         [-1, 64, 128, 128]             128\n            ReLU-194         [-1, 64, 128, 128]               0\n          Conv2d-195         [-1, 64, 128, 128]          36,864\n     BatchNorm2d-196         [-1, 64, 128, 128]             128\n            ReLU-197         [-1, 64, 128, 128]               0\n        Identity-198         [-1, 64, 128, 128]               0\n       Attention-199         [-1, 64, 128, 128]               0\n    DecoderBlock-200         [-1, 64, 128, 128]               0\n        Identity-201          [-1, 320, 64, 64]               0\n       Attention-202          [-1, 320, 64, 64]               0\n          Conv2d-203           [-1, 64, 64, 64]         184,320\n     BatchNorm2d-204           [-1, 64, 64, 64]             128\n            ReLU-205           [-1, 64, 64, 64]               0\n          Conv2d-206           [-1, 64, 64, 64]          36,864\n     BatchNorm2d-207           [-1, 64, 64, 64]             128\n            ReLU-208           [-1, 64, 64, 64]               0\n        Identity-209           [-1, 64, 64, 64]               0\n       Attention-210           [-1, 64, 64, 64]               0\n    DecoderBlock-211           [-1, 64, 64, 64]               0\n        Identity-212        [-1, 256, 128, 128]               0\n       Attention-213        [-1, 256, 128, 128]               0\n          Conv2d-214         [-1, 64, 128, 128]         147,456\n     BatchNorm2d-215         [-1, 64, 128, 128]             128\n            ReLU-216         [-1, 64, 128, 128]               0\n          Conv2d-217         [-1, 64, 128, 128]          36,864\n     BatchNorm2d-218         [-1, 64, 128, 128]             128\n            ReLU-219         [-1, 64, 128, 128]               0\n        Identity-220         [-1, 64, 128, 128]               0\n       Attention-221         [-1, 64, 128, 128]               0\n    DecoderBlock-222         [-1, 64, 128, 128]               0\n        Identity-223        [-1, 320, 128, 128]               0\n       Attention-224        [-1, 320, 128, 128]               0\n          Conv2d-225         [-1, 32, 128, 128]          92,160\n     BatchNorm2d-226         [-1, 32, 128, 128]              64\n            ReLU-227         [-1, 32, 128, 128]               0\n          Conv2d-228         [-1, 32, 128, 128]           9,216\n     BatchNorm2d-229         [-1, 32, 128, 128]              64\n            ReLU-230         [-1, 32, 128, 128]               0\n        Identity-231         [-1, 32, 128, 128]               0\n       Attention-232         [-1, 32, 128, 128]               0\n    DecoderBlock-233         [-1, 32, 128, 128]               0\n          Conv2d-234         [-1, 16, 256, 256]           4,608\n     BatchNorm2d-235         [-1, 16, 256, 256]              32\n            ReLU-236         [-1, 16, 256, 256]               0\n          Conv2d-237         [-1, 16, 256, 256]           2,304\n     BatchNorm2d-238         [-1, 16, 256, 256]              32\n            ReLU-239         [-1, 16, 256, 256]               0\n        Identity-240         [-1, 16, 256, 256]               0\n       Attention-241         [-1, 16, 256, 256]               0\n    DecoderBlock-242         [-1, 16, 256, 256]               0\nUnetPlusPlusDecoder-243         [-1, 16, 256, 256]               0\n          Conv2d-244          [-1, 3, 256, 256]             435\n        Identity-245          [-1, 3, 256, 256]               0\n        Identity-246          [-1, 3, 256, 256]               0\n      Activation-247          [-1, 3, 256, 256]               0\n================================================================\nTotal params: 26,078,899\nTrainable params: 26,078,899\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.75\nForward/backward pass size (MB): 829.25\nParams size (MB): 99.48\nEstimated Total Size (MB): 929.48\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"def initialize_weights(m):\n    if isinstance(m, nn.Conv2d):\n        # Use Xavier/Glorot Initialization for Conv2d layers\n        nn.init.xavier_uniform_(m.weight)\n        if m.bias is not None:\n            nn.init.zeros_(m.bias)\n    elif isinstance(m, nn.ConvTranspose2d):\n        # Xavier Initialization for Transpose Convolutions\n        nn.init.xavier_uniform_(m.weight)\n        if m.bias is not None:\n            nn.init.zeros_(m.bias)\n\n# Apply the initialization function to the model\nmodel.decoder.apply(initialize_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:46:47.950477Z","iopub.execute_input":"2024-11-23T13:46:47.950822Z","iopub.status.idle":"2024-11-23T13:46:47.982901Z","shell.execute_reply.started":"2024-11-23T13:46:47.950792Z","shell.execute_reply":"2024-11-23T13:46:47.982118Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"UnetPlusPlusDecoder(\n  (center): Identity()\n  (blocks): ModuleDict(\n    (x_0_0): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_0_1): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_1_1): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_0_2): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_1_2): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_2_2): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_0_3): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_1_3): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_2_3): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_3_3): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_0_4): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":28},{"cell_type":"markdown","source":"# Wandb para","metadata":{}},{"cell_type":"code","source":"PROJECT = \"BKAI-IGH NeoPolyp\"\nRESUME = \"allow\"\nWANDB_KEY = \"d9d14819dddd8a35a353b5c0b087e0f60d717140\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:46:54.617708Z","iopub.execute_input":"2024-11-23T13:46:54.618555Z","iopub.status.idle":"2024-11-23T13:46:54.622451Z","shell.execute_reply.started":"2024-11-23T13:46:54.618519Z","shell.execute_reply":"2024-11-23T13:46:54.621576Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"# Set up","metadata":{}},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss(reduction='sum')\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:47:02.173055Z","iopub.execute_input":"2024-11-23T13:47:02.173868Z","iopub.status.idle":"2024-11-23T13:47:02.178820Z","shell.execute_reply.started":"2024-11-23T13:47:02.173835Z","shell.execute_reply":"2024-11-23T13:47:02.178029Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"wandb.login(\n    key = \"d9d14819dddd8a35a353b5c0b087e0f60d717140\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:47:05.166924Z","iopub.execute_input":"2024-11-23T13:47:05.167606Z","iopub.status.idle":"2024-11-23T13:47:06.535294Z","shell.execute_reply.started":"2024-11-23T13:47:05.167559Z","shell.execute_reply":"2024-11-23T13:47:06.534518Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"wandb.init(\n    project=PROJECT,\n    resume=RESUME,\n    name=\"init_model\",\n    config={\n        \"learning_rate\": LEARNING_RATE,\n        \"epochs\": NUM_EPOCHS,\n        \"batch_size\": BATCH_SIZE,\n        \"weight_initialization\": \"ImageNet\",\n    },\n)\nwandb.watch(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:47:08.548245Z","iopub.execute_input":"2024-11-23T13:47:08.549312Z","iopub.status.idle":"2024-11-23T13:47:11.789022Z","shell.execute_reply.started":"2024-11-23T13:47:08.549274Z","shell.execute_reply":"2024-11-23T13:47:11.788220Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtr-hoanganh1124\u001b[0m (\u001b[33mtr-hoanganh1124-hanoi-university-of-science-and-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113268477778446, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5199ed230ea6409e9b8074d377278e31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241123_134708-xr3a22v3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/xr3a22v3' target=\"_blank\">init_model</a></strong> to <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp' target=\"_blank\">https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/xr3a22v3' target=\"_blank\">https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/xr3a22v3</a>"},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def dice_coefficient(pred, target, epsilon=1e-6):\n    # Flatten predictions and targets\n    pred = pred.contiguous().view(pred.size(0), -1)\n    target = target.contiguous().view(target.size(0), -1)\n\n    # Compute intersection and union\n    intersection = (pred * target).sum(dim=1)\n    union = pred.sum(dim=1) + target.sum(dim=1)\n\n    # Compute Dice coefficient for each sample and average\n    dice = (2. * intersection + epsilon) / (union + epsilon)\n    return dice.mean().item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:47:14.393447Z","iopub.execute_input":"2024-11-23T13:47:14.393789Z","iopub.status.idle":"2024-11-23T13:47:14.400044Z","shell.execute_reply.started":"2024-11-23T13:47:14.393759Z","shell.execute_reply":"2024-11-23T13:47:14.399356Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"best_val_loss = 99999\n\ndef train_epoch(model, dataloader, optimizer, loss_fn, DEVICE):\n    \n    model.train()\n    running_loss = 0.0\n    for images, masks in dataloader:\n        images, masks = images.to(DEVICE), masks.to(DEVICE)\n        masks = masks.squeeze(dim=1).long()\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(images)\n\n        loss = loss_fn(outputs, masks)  # Ensure masks are float and add channel dimension\n\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    epoch_loss = running_loss / len(dataloader) \n    \n    return epoch_loss\n\ndef validate_epoch(model, dataloader, loss_fn, DEVICE):\n    model.eval()\n    dice_scores = []\n    running_loss = 0.0\n    with torch.no_grad():\n        for images, masks in dataloader:\n            images, masks = images.to(DEVICE), masks.to(DEVICE)\n            masks = masks.squeeze(dim=1).long()\n            \n            # Forward pass\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1)\n\n            # Compute loss\n            loss = loss_fn(outputs, masks)\n            running_loss += loss.item()\n\n            # Calculate Dice coefficient\n            dice = dice_coefficient(preds, masks)\n            dice_scores.append(dice)\n\n    epoch_loss = running_loss / len(dataloader)\n    avg_dice = np.mean(dice_scores)\n    return [epoch_loss, avg_dice]\n\n\n\nfor epoch in range(NUM_EPOCHS):\n    start_time = time.time()\n    \n    train_loss = train_epoch(model, train_loader, optimizer, loss_fn, DEVICE)\n    val_loss, val_dice = validate_epoch(model, val_loader, loss_fn, DEVICE)\n    \n    epoch_time = time.time() - start_time\n    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Time: {epoch_time:.2f}s, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Dice_Coefficient: {val_dice:.4f}\")\n\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), Model_PATH)\n        print(f\"New best checkpoint saved with val_loss: {val_loss:.4f}\")\n\n    # Log results to WandB\n    wandb.log({\n        \"epoch\": epoch,\n        \"train_loss\": train_loss,\n        \"val_loss\": val_loss,\n        \"Dice_Coefficient\": val_dice,\n    })\n\nwandb.finish()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:47:16.820119Z","iopub.execute_input":"2024-11-23T13:47:16.820459Z","iopub.status.idle":"2024-11-23T14:16:10.580585Z","shell.execute_reply.started":"2024-11-23T13:47:16.820432Z","shell.execute_reply":"2024-11-23T14:16:10.579637Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30, Time: 70.13s, Train Loss: 128804.4680, Validation Loss: 56558.3202, Dice_Coefficient: 0.0245\nNew best checkpoint saved with val_loss: 56558.3202\nEpoch 2/30, Time: 55.90s, Train Loss: 36485.5039, Validation Loss: 24159.8023, Dice_Coefficient: 0.6814\nNew best checkpoint saved with val_loss: 24159.8023\nEpoch 3/30, Time: 57.70s, Train Loss: 18306.6752, Validation Loss: 14370.7932, Dice_Coefficient: 0.6814\nNew best checkpoint saved with val_loss: 14370.7932\nEpoch 4/30, Time: 57.11s, Train Loss: 11280.3932, Validation Loss: 8998.5539, Dice_Coefficient: 0.6716\nNew best checkpoint saved with val_loss: 8998.5539\nEpoch 5/30, Time: 56.80s, Train Loss: 7692.2496, Validation Loss: 6414.8261, Dice_Coefficient: 0.6814\nNew best checkpoint saved with val_loss: 6414.8261\nEpoch 6/30, Time: 56.96s, Train Loss: 5697.7831, Validation Loss: 4990.7637, Dice_Coefficient: 0.6716\nNew best checkpoint saved with val_loss: 4990.7637\nEpoch 7/30, Time: 57.17s, Train Loss: 4455.1387, Validation Loss: 3901.9773, Dice_Coefficient: 0.6814\nNew best checkpoint saved with val_loss: 3901.9773\nEpoch 8/30, Time: 57.74s, Train Loss: 3621.9419, Validation Loss: 3259.3747, Dice_Coefficient: 0.6667\nNew best checkpoint saved with val_loss: 3259.3747\nEpoch 9/30, Time: 57.01s, Train Loss: 3035.7629, Validation Loss: 2795.4070, Dice_Coefficient: 0.6618\nNew best checkpoint saved with val_loss: 2795.4070\nEpoch 10/30, Time: 57.02s, Train Loss: 2606.1500, Validation Loss: 2485.9177, Dice_Coefficient: 0.5931\nNew best checkpoint saved with val_loss: 2485.9177\nEpoch 11/30, Time: 57.02s, Train Loss: 2285.3877, Validation Loss: 2150.0279, Dice_Coefficient: 0.6422\nNew best checkpoint saved with val_loss: 2150.0279\nEpoch 12/30, Time: 57.07s, Train Loss: 2037.9610, Validation Loss: 1942.9326, Dice_Coefficient: 0.6471\nNew best checkpoint saved with val_loss: 1942.9326\nEpoch 13/30, Time: 57.01s, Train Loss: 1844.7244, Validation Loss: 1742.1253, Dice_Coefficient: 0.6569\nNew best checkpoint saved with val_loss: 1742.1253\nEpoch 14/30, Time: 57.30s, Train Loss: 1690.4236, Validation Loss: 1553.7757, Dice_Coefficient: 0.6716\nNew best checkpoint saved with val_loss: 1553.7757\nEpoch 15/30, Time: 57.49s, Train Loss: 1559.4068, Validation Loss: 1517.2700, Dice_Coefficient: 0.6618\nNew best checkpoint saved with val_loss: 1517.2700\nEpoch 16/30, Time: 56.90s, Train Loss: 1450.1896, Validation Loss: 1341.6638, Dice_Coefficient: 0.6716\nNew best checkpoint saved with val_loss: 1341.6638\nEpoch 17/30, Time: 57.34s, Train Loss: 1352.7935, Validation Loss: 1278.3906, Dice_Coefficient: 0.6569\nNew best checkpoint saved with val_loss: 1278.3906\nEpoch 18/30, Time: 57.11s, Train Loss: 1269.4236, Validation Loss: 1261.0854, Dice_Coefficient: 0.6716\nNew best checkpoint saved with val_loss: 1261.0854\nEpoch 19/30, Time: 57.11s, Train Loss: 1188.0086, Validation Loss: 1136.8810, Dice_Coefficient: 0.6618\nNew best checkpoint saved with val_loss: 1136.8810\nEpoch 20/30, Time: 57.15s, Train Loss: 1123.7230, Validation Loss: 1173.6384, Dice_Coefficient: 0.6176\nEpoch 21/30, Time: 57.15s, Train Loss: 1050.6699, Validation Loss: 1045.1402, Dice_Coefficient: 0.6618\nNew best checkpoint saved with val_loss: 1045.1402\nEpoch 22/30, Time: 56.85s, Train Loss: 986.4012, Validation Loss: 1031.1068, Dice_Coefficient: 0.6814\nNew best checkpoint saved with val_loss: 1031.1068\nEpoch 23/30, Time: 57.03s, Train Loss: 942.1671, Validation Loss: 951.2981, Dice_Coefficient: 0.6716\nNew best checkpoint saved with val_loss: 951.2981\nEpoch 24/30, Time: 57.16s, Train Loss: 887.6784, Validation Loss: 965.4583, Dice_Coefficient: 0.6618\nEpoch 25/30, Time: 57.49s, Train Loss: 860.1033, Validation Loss: 896.4301, Dice_Coefficient: 0.6814\nNew best checkpoint saved with val_loss: 896.4301\nEpoch 26/30, Time: 57.07s, Train Loss: 806.7120, Validation Loss: 868.1601, Dice_Coefficient: 0.6618\nNew best checkpoint saved with val_loss: 868.1601\nEpoch 27/30, Time: 56.79s, Train Loss: 772.1916, Validation Loss: 824.3822, Dice_Coefficient: 0.6814\nNew best checkpoint saved with val_loss: 824.3822\nEpoch 28/30, Time: 56.98s, Train Loss: 742.4651, Validation Loss: 823.5671, Dice_Coefficient: 0.6716\nNew best checkpoint saved with val_loss: 823.5671\nEpoch 29/30, Time: 56.98s, Train Loss: 708.7093, Validation Loss: 781.1856, Dice_Coefficient: 0.6716\nNew best checkpoint saved with val_loss: 781.1856\nEpoch 30/30, Time: 56.99s, Train Loss: 681.4841, Validation Loss: 792.1016, Dice_Coefficient: 0.6716\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.270 MB of 0.270 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Dice_Coefficient</td><td>▁████████▇█████████▇██████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Dice_Coefficient</td><td>0.67157</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>train_loss</td><td>681.48415</td></tr><tr><td>val_loss</td><td>792.10162</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">init_model</strong> at: <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/xr3a22v3' target=\"_blank\">https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/xr3a22v3</a><br/> View project at: <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp' target=\"_blank\">https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241123_134708-xr3a22v3/logs</code>"},"metadata":{}}],"execution_count":34},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load(Model_PATH))\nmodel = model.to(DEVICE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TestData(Dataset):\n    def __init__(self, images_path, transform):\n\n        self.image_paths = image_paths\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img_path = self.images_list[index]\n        data = Image.open(img_path)\n        h = data.size[1]\n        w = data.size[0]\n        data = self.transform(data) / 255        \n        return data, img_path, h, w\n    \n    def __len__(self):\n        return len(self.images_list)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def resizeprediction(pred, original_size):\n    h, w = original_size\n    return cv2.resize(pred, (w, h), interpolation=cv2.INTER_NEAREST)\n\nsubmission_data = []\nfor test_image in os.listdir(TEST_IMAGES_DIR):\n    img_path = os.path.join(TEST_IMAGES_DIR, test_image)\n    original_img = cv2.imread(img_path)\n    h, w = original_img.shape[:2]\n\n    # Preprocess test image\n    img = cv2.resize(original_img, (IMG_WIDTH, IMG_HEIGHT)) / 255.0\n    pred = model.predict(np.expand_dims(img, axis=0))[0]\n\n    # Resize predictions back to original size\n    for class_id in range(NUM_CLASSES):\n        class_pred = resize_prediction((pred[:, :, class_id] > 0.5).astype(np.uint8), (h, w))\n        rle = rle_encode_one_mask(class_pred)\n        submission_data.append({'Id': f\"{test_image.split('.')[0]}{class_id}\", 'Expected': rle})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport os\n\ndef rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\ndef rle_encode_one_mask(mask):\n    pixels = mask.flatten()\n    pixels[pixels > 0] = 255\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    \n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    return rle_to_string(rle)\n\ndef rle2mask(mask_rle, shape=(3,3)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\n\ndef mask2string(dir):\n    ## mask --> string\n    strings = []\n    ids = []\n    ws, hs = [[] for i in range(2)]\n    for image_id in os.listdir(dir):\n        id = image_id.split('.')[0]\n        path = os.path.join(dir, image_id)\n        print(path)\n        img = cv2.imread(path)[:,:,::-1]\n        h, w = img.shape[0], img.shape[1]\n        for channel in range(2):\n            ws.append(w)\n            hs.append(h)\n            ids.append(f'{id}_{channel}')\n            string = rle_encode_one_mask(img[:,:,channel])\n            strings.append(string)\n    r = {\n        'ids': ids,\n        'strings': strings,\n    }\n    return r\n\n\nMASK_DIR_PATH = '' # change this to the path to your output mask folder\ndir = MASK_DIR_PATH\nres = mask2string(dir)\ndf = pd.DataFrame(columns=['Id', 'Expected'])\ndf['Id'] = res['ids']\ndf['Expected'] = res['strings']\n\ndf.to_csv(r'output.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}