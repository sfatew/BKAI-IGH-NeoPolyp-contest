{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":30892,"databundleVersionId":2715462,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:33:49.270081Z","iopub.execute_input":"2024-11-23T09:33:49.270871Z","iopub.status.idle":"2024-11-23T09:33:50.407287Z","shell.execute_reply.started":"2024-11-23T09:33:49.270828Z","shell.execute_reply":"2024-11-23T09:33:50.406264Z"}},"outputs":[{"name":"stdout","text":"Sat Nov 23 09:33:50 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   68C    P0             33W /   70W |    2153MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   42C    P8             12W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"!pip install torchsummary\n!pip install torchgeometry","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:33:50.409260Z","iopub.execute_input":"2024-11-23T09:33:50.409557Z","iopub.status.idle":"2024-11-23T09:34:06.888368Z","shell.execute_reply.started":"2024-11-23T09:33:50.409530Z","shell.execute_reply":"2024-11-23T09:34:06.887378Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\nRequirement already satisfied: torchgeometry in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torchgeometry) (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->torchgeometry) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->torchgeometry) (1.3.0)\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"!pip install segmentation-models-pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:06.890035Z","iopub.execute_input":"2024-11-23T09:34:06.890445Z","iopub.status.idle":"2024-11-23T09:34:15.074726Z","shell.execute_reply.started":"2024-11-23T09:34:06.890404Z","shell.execute_reply":"2024-11-23T09:34:15.073698Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: segmentation-models-pytorch in /opt/conda/lib/python3.10/site-packages (0.3.4)\nRequirement already satisfied: efficientnet-pytorch==0.7.1 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.1)\nRequirement already satisfied: huggingface-hub>=0.24.6 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.25.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.3.0)\nRequirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (1.16.0)\nRequirement already satisfied: timm==0.9.7 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.9.7)\nRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.19.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.4.0)\nRequirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (4.12.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport albumentations as A\n\nimport segmentation_models_pytorch as smp\n\nimport cv2\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport time\nfrom PIL import Image\nimport os\n\nimport wandb\nfrom torchsummary import summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:15.077045Z","iopub.execute_input":"2024-11-23T09:34:15.077370Z","iopub.status.idle":"2024-11-23T09:34:15.083841Z","shell.execute_reply.started":"2024-11-23T09:34:15.077341Z","shell.execute_reply":"2024-11-23T09:34:15.083169Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 6","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:15.084679Z","iopub.execute_input":"2024-11-23T09:34:15.084926Z","iopub.status.idle":"2024-11-23T09:34:15.105005Z","shell.execute_reply.started":"2024-11-23T09:34:15.084902Z","shell.execute_reply":"2024-11-23T09:34:15.104407Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"IMAGES_PATH = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\nMASKS_PATH =  \"/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt/\"\nTEST_PATH = \"/kaggle/input/bkai-igh-neopolyp/test/test/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:15.106056Z","iopub.execute_input":"2024-11-23T09:34:15.106310Z","iopub.status.idle":"2024-11-23T09:34:15.117729Z","shell.execute_reply.started":"2024-11-23T09:34:15.106286Z","shell.execute_reply":"2024-11-23T09:34:15.117153Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"### transform","metadata":{}},{"cell_type":"code","source":"#transf with ImageNet statistics\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:15.119037Z","iopub.execute_input":"2024-11-23T09:34:15.119837Z","iopub.status.idle":"2024-11-23T09:34:15.130795Z","shell.execute_reply.started":"2024-11-23T09:34:15.119798Z","shell.execute_reply":"2024-11-23T09:34:15.130172Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# transf with calculated mean, std\n#init_transform = transforms.ToTensor(),\n\n#img_tr = init_transform(img)\n \n# calculate mean and std of each RGB layer\n#mean, std = img_tr.mean([1,2]), img_tr.std([1,2])\n\n#transform_norm = transforms.Compose([\n    #transforms.Resize((256, 256)),\n    #transforms.ToTensor(),\n    #transforms.Normalize(mean, std)\n#])\n \n# get normalized image\n#img_normalized = transform_norm(img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:15.131757Z","iopub.execute_input":"2024-11-23T09:34:15.132059Z","iopub.status.idle":"2024-11-23T09:34:15.142002Z","shell.execute_reply.started":"2024-11-23T09:34:15.132034Z","shell.execute_reply":"2024-11-23T09:34:15.141434Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"### Data","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, image_paths, mask_paths, resize = (256,256), transform=None, color_map=None):\n        self.image_paths = image_paths\n        self.mask_paths = mask_paths\n        self.resize = resize\n        self.transform = transform\n        self.color_map = color_map or {\n            (255, 0, 0): 1,  # Red (neoplastic polyps)\n            (0, 255, 0): 2   # Green (non-neoplastic polyps)\n        }\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def encode_mask(self, mask):\n        \"\"\"\n        Encode RGB mask into single-channel class labels.\n        \"\"\"\n        encoded_mask = np.zeros(mask.shape[:2], dtype=np.uint8)\n        for color, label in self.color_map.items():\n            condition = (mask[:, :, 0] == color[0]) & (mask[:, :, 1] == color[1]) & (mask[:, :, 2] == color[2])\n            encoded_mask[condition] = label\n        return encoded_mask\n\n    def __getitem__(self, idx):\n\n        img_path = self.image_paths[idx]\n        mask_path = self.mask_paths[idx]\n\n        img = Image.open(img_path)\n\n        mask = cv2.imread(mask_path)\n        if mask is None:\n            raise FileNotFoundError(f\"Mask not found at {mask_path}\")\n        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n        mask = self.encode_mask(mask)\n        mask = cv2.resize(mask, self.resize)\n\n        if self.transform:\n            img = self.transform(img)\n   \n        return img, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:15.143271Z","iopub.execute_input":"2024-11-23T09:34:15.143527Z","iopub.status.idle":"2024-11-23T09:34:15.152411Z","shell.execute_reply.started":"2024-11-23T09:34:15.143503Z","shell.execute_reply":"2024-11-23T09:34:15.151604Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"image_paths = []\nfor root, dirs, files in os.walk(IMAGES_PATH):\n    for file in files:\n        path = os.path.join(root,file)\n        image_paths.append(path)\n        \nlen(image_paths)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:15.154909Z","iopub.execute_input":"2024-11-23T09:34:15.155167Z","iopub.status.idle":"2024-11-23T09:34:15.672402Z","shell.execute_reply.started":"2024-11-23T09:34:15.155102Z","shell.execute_reply":"2024-11-23T09:34:15.671696Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"mask_paths = []\nfor root, dirs, files in os.walk(MASKS_PATH):\n    for file in files:\n        path = os.path.join(root,file)\n        mask_paths.append(path)\n        \nlen(mask_paths)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:15.673294Z","iopub.execute_input":"2024-11-23T09:34:15.673510Z","iopub.status.idle":"2024-11-23T09:34:16.172571Z","shell.execute_reply.started":"2024-11-23T09:34:15.673488Z","shell.execute_reply":"2024-11-23T09:34:16.171707Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"init_dataset = CustomDataset(image_paths, mask_paths, transform = transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:16.173526Z","iopub.execute_input":"2024-11-23T09:34:16.173796Z","iopub.status.idle":"2024-11-23T09:34:16.178640Z","shell.execute_reply.started":"2024-11-23T09:34:16.173770Z","shell.execute_reply":"2024-11-23T09:34:16.177895Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"print(len(init_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:16.179713Z","iopub.execute_input":"2024-11-23T09:34:16.179943Z","iopub.status.idle":"2024-11-23T09:34:16.192940Z","shell.execute_reply.started":"2024-11-23T09:34:16.179920Z","shell.execute_reply":"2024-11-23T09:34:16.192176Z"}},"outputs":[{"name":"stdout","text":"1000\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"train_size = int(len(init_dataset) * 0.80)\nvalid_size = len(init_dataset) - train_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:16.193891Z","iopub.execute_input":"2024-11-23T09:34:16.194137Z","iopub.status.idle":"2024-11-23T09:34:16.203627Z","shell.execute_reply.started":"2024-11-23T09:34:16.194090Z","shell.execute_reply":"2024-11-23T09:34:16.202831Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:16.204766Z","iopub.execute_input":"2024-11-23T09:34:16.205015Z","iopub.status.idle":"2024-11-23T09:34:16.217346Z","shell.execute_reply.started":"2024-11-23T09:34:16.204992Z","shell.execute_reply":"2024-11-23T09:34:16.216587Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f42c40b0d90>"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"train_set, valid_set = random_split(init_dataset, [train_size, valid_size])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:16.218337Z","iopub.execute_input":"2024-11-23T09:34:16.218676Z","iopub.status.idle":"2024-11-23T09:34:16.228017Z","shell.execute_reply.started":"2024-11-23T09:34:16.218650Z","shell.execute_reply":"2024-11-23T09:34:16.227136Z"}},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":"### Data Loader","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:16.229366Z","iopub.execute_input":"2024-11-23T09:34:16.230002Z","iopub.status.idle":"2024-11-23T09:34:16.245260Z","shell.execute_reply.started":"2024-11-23T09:34:16.229962Z","shell.execute_reply":"2024-11-23T09:34:16.244648Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"print(len(train_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:16.246326Z","iopub.execute_input":"2024-11-23T09:34:16.246636Z","iopub.status.idle":"2024-11-23T09:34:16.258761Z","shell.execute_reply.started":"2024-11-23T09:34:16.246601Z","shell.execute_reply":"2024-11-23T09:34:16.258066Z"}},"outputs":[{"name":"stdout","text":"134\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"# Hyperparameters","metadata":{}},{"cell_type":"code","source":"NUM_CLASSES = 3\nNUM_EPOCHS = 50\nLEARNING_RATE = 1e-04\n\nModel_PATH = '/kaggle/working/unet-model.pth'\n\nPreTrained_path = \"/kaggle/input/unet-checkpoint/unet-model.pth\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:16.259553Z","iopub.execute_input":"2024-11-23T09:34:16.259824Z","iopub.status.idle":"2024-11-23T09:34:16.270167Z","shell.execute_reply.started":"2024-11-23T09:34:16.259799Z","shell.execute_reply":"2024-11-23T09:34:16.269385Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nDEVICE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:16.271033Z","iopub.execute_input":"2024-11-23T09:34:16.271277Z","iopub.status.idle":"2024-11-23T09:34:16.285368Z","shell.execute_reply.started":"2024-11-23T09:34:16.271254Z","shell.execute_reply":"2024-11-23T09:34:16.284685Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":47},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"UNET = smp.UnetPlusPlus(\n    encoder_name=\"resnet34\",        \n    encoder_weights=\"imagenet\",      \n    decoder_use_batchnorm=True,\n    in_channels=3, \n    classes= NUM_CLASSES,\n    #activation= 'softmax'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:16.286304Z","iopub.execute_input":"2024-11-23T09:34:16.286612Z","iopub.status.idle":"2024-11-23T09:34:16.932577Z","shell.execute_reply.started":"2024-11-23T09:34:16.286576Z","shell.execute_reply":"2024-11-23T09:34:16.931812Z"}},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"# Wandb para","metadata":{}},{"cell_type":"code","source":"model = UNET.to(DEVICE)\nsummary(model, (3, 256, 256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:16.933790Z","iopub.execute_input":"2024-11-23T09:34:16.934158Z","iopub.status.idle":"2024-11-23T09:34:17.062060Z","shell.execute_reply.started":"2024-11-23T09:34:16.934102Z","shell.execute_reply":"2024-11-23T09:34:17.061159Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 128, 128]           9,408\n       BatchNorm2d-2         [-1, 64, 128, 128]             128\n              ReLU-3         [-1, 64, 128, 128]               0\n         MaxPool2d-4           [-1, 64, 64, 64]               0\n            Conv2d-5           [-1, 64, 64, 64]          36,864\n       BatchNorm2d-6           [-1, 64, 64, 64]             128\n              ReLU-7           [-1, 64, 64, 64]               0\n            Conv2d-8           [-1, 64, 64, 64]          36,864\n       BatchNorm2d-9           [-1, 64, 64, 64]             128\n             ReLU-10           [-1, 64, 64, 64]               0\n       BasicBlock-11           [-1, 64, 64, 64]               0\n           Conv2d-12           [-1, 64, 64, 64]          36,864\n      BatchNorm2d-13           [-1, 64, 64, 64]             128\n             ReLU-14           [-1, 64, 64, 64]               0\n           Conv2d-15           [-1, 64, 64, 64]          36,864\n      BatchNorm2d-16           [-1, 64, 64, 64]             128\n             ReLU-17           [-1, 64, 64, 64]               0\n       BasicBlock-18           [-1, 64, 64, 64]               0\n           Conv2d-19           [-1, 64, 64, 64]          36,864\n      BatchNorm2d-20           [-1, 64, 64, 64]             128\n             ReLU-21           [-1, 64, 64, 64]               0\n           Conv2d-22           [-1, 64, 64, 64]          36,864\n      BatchNorm2d-23           [-1, 64, 64, 64]             128\n             ReLU-24           [-1, 64, 64, 64]               0\n       BasicBlock-25           [-1, 64, 64, 64]               0\n           Conv2d-26          [-1, 128, 32, 32]          73,728\n      BatchNorm2d-27          [-1, 128, 32, 32]             256\n             ReLU-28          [-1, 128, 32, 32]               0\n           Conv2d-29          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-30          [-1, 128, 32, 32]             256\n           Conv2d-31          [-1, 128, 32, 32]           8,192\n      BatchNorm2d-32          [-1, 128, 32, 32]             256\n             ReLU-33          [-1, 128, 32, 32]               0\n       BasicBlock-34          [-1, 128, 32, 32]               0\n           Conv2d-35          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-36          [-1, 128, 32, 32]             256\n             ReLU-37          [-1, 128, 32, 32]               0\n           Conv2d-38          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-39          [-1, 128, 32, 32]             256\n             ReLU-40          [-1, 128, 32, 32]               0\n       BasicBlock-41          [-1, 128, 32, 32]               0\n           Conv2d-42          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-43          [-1, 128, 32, 32]             256\n             ReLU-44          [-1, 128, 32, 32]               0\n           Conv2d-45          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-46          [-1, 128, 32, 32]             256\n             ReLU-47          [-1, 128, 32, 32]               0\n       BasicBlock-48          [-1, 128, 32, 32]               0\n           Conv2d-49          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-50          [-1, 128, 32, 32]             256\n             ReLU-51          [-1, 128, 32, 32]               0\n           Conv2d-52          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-53          [-1, 128, 32, 32]             256\n             ReLU-54          [-1, 128, 32, 32]               0\n       BasicBlock-55          [-1, 128, 32, 32]               0\n           Conv2d-56          [-1, 256, 16, 16]         294,912\n      BatchNorm2d-57          [-1, 256, 16, 16]             512\n             ReLU-58          [-1, 256, 16, 16]               0\n           Conv2d-59          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-60          [-1, 256, 16, 16]             512\n           Conv2d-61          [-1, 256, 16, 16]          32,768\n      BatchNorm2d-62          [-1, 256, 16, 16]             512\n             ReLU-63          [-1, 256, 16, 16]               0\n       BasicBlock-64          [-1, 256, 16, 16]               0\n           Conv2d-65          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-66          [-1, 256, 16, 16]             512\n             ReLU-67          [-1, 256, 16, 16]               0\n           Conv2d-68          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-69          [-1, 256, 16, 16]             512\n             ReLU-70          [-1, 256, 16, 16]               0\n       BasicBlock-71          [-1, 256, 16, 16]               0\n           Conv2d-72          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-73          [-1, 256, 16, 16]             512\n             ReLU-74          [-1, 256, 16, 16]               0\n           Conv2d-75          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-76          [-1, 256, 16, 16]             512\n             ReLU-77          [-1, 256, 16, 16]               0\n       BasicBlock-78          [-1, 256, 16, 16]               0\n           Conv2d-79          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-80          [-1, 256, 16, 16]             512\n             ReLU-81          [-1, 256, 16, 16]               0\n           Conv2d-82          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-83          [-1, 256, 16, 16]             512\n             ReLU-84          [-1, 256, 16, 16]               0\n       BasicBlock-85          [-1, 256, 16, 16]               0\n           Conv2d-86          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-87          [-1, 256, 16, 16]             512\n             ReLU-88          [-1, 256, 16, 16]               0\n           Conv2d-89          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-90          [-1, 256, 16, 16]             512\n             ReLU-91          [-1, 256, 16, 16]               0\n       BasicBlock-92          [-1, 256, 16, 16]               0\n           Conv2d-93          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-94          [-1, 256, 16, 16]             512\n             ReLU-95          [-1, 256, 16, 16]               0\n           Conv2d-96          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-97          [-1, 256, 16, 16]             512\n             ReLU-98          [-1, 256, 16, 16]               0\n       BasicBlock-99          [-1, 256, 16, 16]               0\n          Conv2d-100            [-1, 512, 8, 8]       1,179,648\n     BatchNorm2d-101            [-1, 512, 8, 8]           1,024\n            ReLU-102            [-1, 512, 8, 8]               0\n          Conv2d-103            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-104            [-1, 512, 8, 8]           1,024\n          Conv2d-105            [-1, 512, 8, 8]         131,072\n     BatchNorm2d-106            [-1, 512, 8, 8]           1,024\n            ReLU-107            [-1, 512, 8, 8]               0\n      BasicBlock-108            [-1, 512, 8, 8]               0\n          Conv2d-109            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-110            [-1, 512, 8, 8]           1,024\n            ReLU-111            [-1, 512, 8, 8]               0\n          Conv2d-112            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-113            [-1, 512, 8, 8]           1,024\n            ReLU-114            [-1, 512, 8, 8]               0\n      BasicBlock-115            [-1, 512, 8, 8]               0\n          Conv2d-116            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-117            [-1, 512, 8, 8]           1,024\n            ReLU-118            [-1, 512, 8, 8]               0\n          Conv2d-119            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-120            [-1, 512, 8, 8]           1,024\n            ReLU-121            [-1, 512, 8, 8]               0\n      BasicBlock-122            [-1, 512, 8, 8]               0\n   ResNetEncoder-123  [[-1, 3, 256, 256], [-1, 64, 128, 128], [-1, 64, 64, 64], [-1, 128, 32, 32], [-1, 256, 16, 16], [-1, 512, 8, 8]]               0\n        Identity-124          [-1, 768, 16, 16]               0\n       Attention-125          [-1, 768, 16, 16]               0\n          Conv2d-126          [-1, 256, 16, 16]       1,769,472\n     BatchNorm2d-127          [-1, 256, 16, 16]             512\n            ReLU-128          [-1, 256, 16, 16]               0\n          Conv2d-129          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-130          [-1, 256, 16, 16]             512\n            ReLU-131          [-1, 256, 16, 16]               0\n        Identity-132          [-1, 256, 16, 16]               0\n       Attention-133          [-1, 256, 16, 16]               0\n    DecoderBlock-134          [-1, 256, 16, 16]               0\n        Identity-135          [-1, 384, 32, 32]               0\n       Attention-136          [-1, 384, 32, 32]               0\n          Conv2d-137          [-1, 128, 32, 32]         442,368\n     BatchNorm2d-138          [-1, 128, 32, 32]             256\n            ReLU-139          [-1, 128, 32, 32]               0\n          Conv2d-140          [-1, 128, 32, 32]         147,456\n     BatchNorm2d-141          [-1, 128, 32, 32]             256\n            ReLU-142          [-1, 128, 32, 32]               0\n        Identity-143          [-1, 128, 32, 32]               0\n       Attention-144          [-1, 128, 32, 32]               0\n    DecoderBlock-145          [-1, 128, 32, 32]               0\n        Identity-146          [-1, 192, 64, 64]               0\n       Attention-147          [-1, 192, 64, 64]               0\n          Conv2d-148           [-1, 64, 64, 64]         110,592\n     BatchNorm2d-149           [-1, 64, 64, 64]             128\n            ReLU-150           [-1, 64, 64, 64]               0\n          Conv2d-151           [-1, 64, 64, 64]          36,864\n     BatchNorm2d-152           [-1, 64, 64, 64]             128\n            ReLU-153           [-1, 64, 64, 64]               0\n        Identity-154           [-1, 64, 64, 64]               0\n       Attention-155           [-1, 64, 64, 64]               0\n    DecoderBlock-156           [-1, 64, 64, 64]               0\n        Identity-157        [-1, 128, 128, 128]               0\n       Attention-158        [-1, 128, 128, 128]               0\n          Conv2d-159         [-1, 64, 128, 128]          73,728\n     BatchNorm2d-160         [-1, 64, 128, 128]             128\n            ReLU-161         [-1, 64, 128, 128]               0\n          Conv2d-162         [-1, 64, 128, 128]          36,864\n     BatchNorm2d-163         [-1, 64, 128, 128]             128\n            ReLU-164         [-1, 64, 128, 128]               0\n        Identity-165         [-1, 64, 128, 128]               0\n       Attention-166         [-1, 64, 128, 128]               0\n    DecoderBlock-167         [-1, 64, 128, 128]               0\n        Identity-168          [-1, 512, 32, 32]               0\n       Attention-169          [-1, 512, 32, 32]               0\n          Conv2d-170          [-1, 128, 32, 32]         589,824\n     BatchNorm2d-171          [-1, 128, 32, 32]             256\n            ReLU-172          [-1, 128, 32, 32]               0\n          Conv2d-173          [-1, 128, 32, 32]         147,456\n     BatchNorm2d-174          [-1, 128, 32, 32]             256\n            ReLU-175          [-1, 128, 32, 32]               0\n        Identity-176          [-1, 128, 32, 32]               0\n       Attention-177          [-1, 128, 32, 32]               0\n    DecoderBlock-178          [-1, 128, 32, 32]               0\n        Identity-179          [-1, 256, 64, 64]               0\n       Attention-180          [-1, 256, 64, 64]               0\n          Conv2d-181           [-1, 64, 64, 64]         147,456\n     BatchNorm2d-182           [-1, 64, 64, 64]             128\n            ReLU-183           [-1, 64, 64, 64]               0\n          Conv2d-184           [-1, 64, 64, 64]          36,864\n     BatchNorm2d-185           [-1, 64, 64, 64]             128\n            ReLU-186           [-1, 64, 64, 64]               0\n        Identity-187           [-1, 64, 64, 64]               0\n       Attention-188           [-1, 64, 64, 64]               0\n    DecoderBlock-189           [-1, 64, 64, 64]               0\n        Identity-190        [-1, 192, 128, 128]               0\n       Attention-191        [-1, 192, 128, 128]               0\n          Conv2d-192         [-1, 64, 128, 128]         110,592\n     BatchNorm2d-193         [-1, 64, 128, 128]             128\n            ReLU-194         [-1, 64, 128, 128]               0\n          Conv2d-195         [-1, 64, 128, 128]          36,864\n     BatchNorm2d-196         [-1, 64, 128, 128]             128\n            ReLU-197         [-1, 64, 128, 128]               0\n        Identity-198         [-1, 64, 128, 128]               0\n       Attention-199         [-1, 64, 128, 128]               0\n    DecoderBlock-200         [-1, 64, 128, 128]               0\n        Identity-201          [-1, 320, 64, 64]               0\n       Attention-202          [-1, 320, 64, 64]               0\n          Conv2d-203           [-1, 64, 64, 64]         184,320\n     BatchNorm2d-204           [-1, 64, 64, 64]             128\n            ReLU-205           [-1, 64, 64, 64]               0\n          Conv2d-206           [-1, 64, 64, 64]          36,864\n     BatchNorm2d-207           [-1, 64, 64, 64]             128\n            ReLU-208           [-1, 64, 64, 64]               0\n        Identity-209           [-1, 64, 64, 64]               0\n       Attention-210           [-1, 64, 64, 64]               0\n    DecoderBlock-211           [-1, 64, 64, 64]               0\n        Identity-212        [-1, 256, 128, 128]               0\n       Attention-213        [-1, 256, 128, 128]               0\n          Conv2d-214         [-1, 64, 128, 128]         147,456\n     BatchNorm2d-215         [-1, 64, 128, 128]             128\n            ReLU-216         [-1, 64, 128, 128]               0\n          Conv2d-217         [-1, 64, 128, 128]          36,864\n     BatchNorm2d-218         [-1, 64, 128, 128]             128\n            ReLU-219         [-1, 64, 128, 128]               0\n        Identity-220         [-1, 64, 128, 128]               0\n       Attention-221         [-1, 64, 128, 128]               0\n    DecoderBlock-222         [-1, 64, 128, 128]               0\n        Identity-223        [-1, 320, 128, 128]               0\n       Attention-224        [-1, 320, 128, 128]               0\n          Conv2d-225         [-1, 32, 128, 128]          92,160\n     BatchNorm2d-226         [-1, 32, 128, 128]              64\n            ReLU-227         [-1, 32, 128, 128]               0\n          Conv2d-228         [-1, 32, 128, 128]           9,216\n     BatchNorm2d-229         [-1, 32, 128, 128]              64\n            ReLU-230         [-1, 32, 128, 128]               0\n        Identity-231         [-1, 32, 128, 128]               0\n       Attention-232         [-1, 32, 128, 128]               0\n    DecoderBlock-233         [-1, 32, 128, 128]               0\n          Conv2d-234         [-1, 16, 256, 256]           4,608\n     BatchNorm2d-235         [-1, 16, 256, 256]              32\n            ReLU-236         [-1, 16, 256, 256]               0\n          Conv2d-237         [-1, 16, 256, 256]           2,304\n     BatchNorm2d-238         [-1, 16, 256, 256]              32\n            ReLU-239         [-1, 16, 256, 256]               0\n        Identity-240         [-1, 16, 256, 256]               0\n       Attention-241         [-1, 16, 256, 256]               0\n    DecoderBlock-242         [-1, 16, 256, 256]               0\nUnetPlusPlusDecoder-243         [-1, 16, 256, 256]               0\n          Conv2d-244          [-1, 3, 256, 256]             435\n        Identity-245          [-1, 3, 256, 256]               0\n        Identity-246          [-1, 3, 256, 256]               0\n      Activation-247          [-1, 3, 256, 256]               0\n================================================================\nTotal params: 26,078,899\nTrainable params: 26,078,899\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.75\nForward/backward pass size (MB): 829.25\nParams size (MB): 99.48\nEstimated Total Size (MB): 929.48\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"PROJECT = \"BKAI-IGH NeoPolyp\"\nRESUME = \"allow\"\nWANDB_KEY = \"d9d14819dddd8a35a353b5c0b087e0f60d717140\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:17.062992Z","iopub.execute_input":"2024-11-23T09:34:17.063262Z","iopub.status.idle":"2024-11-23T09:34:17.067809Z","shell.execute_reply.started":"2024-11-23T09:34:17.063237Z","shell.execute_reply":"2024-11-23T09:34:17.067076Z"}},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":"# Set up","metadata":{}},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss(reduction='sum')\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:17.068860Z","iopub.execute_input":"2024-11-23T09:34:17.069113Z","iopub.status.idle":"2024-11-23T09:34:17.079776Z","shell.execute_reply.started":"2024-11-23T09:34:17.069089Z","shell.execute_reply":"2024-11-23T09:34:17.079083Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"wandb.login(\n    key = \"d9d14819dddd8a35a353b5c0b087e0f60d717140\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:17.080720Z","iopub.execute_input":"2024-11-23T09:34:17.080960Z","iopub.status.idle":"2024-11-23T09:34:17.089930Z","shell.execute_reply.started":"2024-11-23T09:34:17.080936Z","shell.execute_reply":"2024-11-23T09:34:17.089277Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"wandb.init(\n    project=PROJECT,\n    resume=RESUME,\n    name=\"init_model\",\n    config={\n        \"learning_rate\": LEARNING_RATE,\n        \"epochs\": NUM_EPOCHS,\n        \"batch_size\": BATCH_SIZE,\n        \"weight_initialization\": \"ImageNet\",\n    },\n)\nwandb.watch(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:34:17.090885Z","iopub.execute_input":"2024-11-23T09:34:17.091137Z","iopub.status.idle":"2024-11-23T09:34:19.931518Z","shell.execute_reply.started":"2024-11-23T09:34:17.091091Z","shell.execute_reply":"2024-11-23T09:34:19.930611Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:rshxivjc) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.040 MB of 0.040 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train_accuracy</td><td>0.89387</td></tr><tr><td>train_loss</td><td>209640.26679</td></tr><tr><td>val_accuracy</td><td>0.99852</td></tr><tr><td>val_loss</td><td>100210.56009</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">init_model</strong> at: <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/rshxivjc' target=\"_blank\">https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/rshxivjc</a><br/> View project at: <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp' target=\"_blank\">https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241123_091809-rshxivjc/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:rshxivjc). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241123_093417-qaa4s4vh</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/qaa4s4vh' target=\"_blank\">init_model</a></strong> to <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp' target=\"_blank\">https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/qaa4s4vh' target=\"_blank\">https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/qaa4s4vh</a>"},"metadata":{}},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}],"execution_count":53},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"best_val_loss = 99999\n\ndef train_epoch(model, dataloader, optimizer, loss_fn, DEVICE):\n    \n    model.train()\n    running_loss = 0.0\n    for images, masks in dataloader:\n        images, masks = images.to(DEVICE), masks.to(DEVICE)\n        masks = masks.squeeze(dim=1).long()\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(images)\n\n        loss = loss_fn(outputs, masks)  # Ensure masks are float and add channel dimension\n\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    epoch_loss = running_loss / len(dataloader) \n    \n    return epoch_loss\n\ndef validate_epoch(model, dataloader, loss_fn, DEVICE):\n    model.eval()\n    running_loss = 0.0\n    with torch.no_grad():\n        for images, masks in dataloader:\n            images, masks = images.to(DEVICE), masks.to(DEVICE)\n            masks = masks.squeeze(dim=1).long()\n            \n            # Forward pass\n            outputs = model(images)\n\n            # Compute loss\n            loss = loss_fn(outputs, masks)\n            running_loss += loss.item()\n\n    epoch_loss = running_loss / len(dataloader)\n    return epoch_loss\n\n\n\nfor epoch in range(NUM_EPOCHS):\n    start_time = time.time()\n    \n    train_loss = train_epoch(model, train_loader, optimizer, loss_fn, DEVICE)\n    val_loss = validate_epoch(model, val_loader, loss_fn, DEVICE)\n    \n    epoch_time = time.time() - start_time\n    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Time: {epoch_time:.2f}s, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n\n\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), CHECKPOINT_PATH)\n        print(f\"New best checkpoint saved with val_loss: {val_loss:.4f}\")\n\n    # Log results to WandB\n    wandb.log({\n        \"epoch\": epoch,\n        \"train_loss\": train_loss,\n        \"val_loss\": val_loss,\n    })\n\nwandb.finish()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:48:09.445775Z","iopub.execute_input":"2024-11-23T09:48:09.446587Z","iopub.status.idle":"2024-11-23T09:52:56.263197Z","shell.execute_reply.started":"2024-11-23T09:48:09.446550Z","shell.execute_reply":"2024-11-23T09:52:56.261878Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50, Time: 63.79s, Train Loss: 209950.2728, Validation Loss: 102251.2019\nEpoch 2/50, Time: 64.75s, Train Loss: 74707.1964, Validation Loss: 50984.9011\nNew best checkpoint saved with val_loss: 50984.9011\nEpoch 3/50, Time: 64.31s, Train Loss: 39987.9116, Validation Loss: 29773.4577\nNew best checkpoint saved with val_loss: 29773.4577\nEpoch 4/50, Time: 63.70s, Train Loss: 23000.6644, Validation Loss: 17592.0787\nNew best checkpoint saved with val_loss: 17592.0787\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[60], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[1;32m     49\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 51\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m validate_epoch(model, val_loader, loss_fn, DEVICE)\n\u001b[1;32m     54\u001b[0m     epoch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n","Cell \u001b[0;32mIn[60], line 22\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, optimizer, loss_fn, DEVICE)\u001b[0m\n\u001b[1;32m     19\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 22\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader) \n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epoch_loss\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":60},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"def evaluate(model, dataloader, device):\n    model.eval()\n    with torch.no_grad():\n        for images, masks in dataloader:\n            images = images.to(device)\n            masks = masks.to(device)\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1)\n            break  # Just show the first batch\nevaluate(model, val_dataloader, device)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntorch.save(model.state_dict(), \"unet_model.pth\")\n\nmodel.load_state_dict(torch.load(\"unet_model.pth\"))\nmodel = model.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}