{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":30892,"databundleVersionId":2715462,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:54:03.908929Z","iopub.execute_input":"2024-11-24T16:54:03.909265Z","iopub.status.idle":"2024-11-24T16:54:05.019058Z","shell.execute_reply.started":"2024-11-24T16:54:03.909234Z","shell.execute_reply":"2024-11-24T16:54:05.018175Z"}},"outputs":[{"name":"stdout","text":"Sun Nov 24 16:54:04 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   38C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   36C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install torchsummary\n!pip install torchgeometry","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:54:08.429498Z","iopub.execute_input":"2024-11-24T16:54:08.430254Z","iopub.status.idle":"2024-11-24T16:54:26.495923Z","shell.execute_reply.started":"2024-11-24T16:54:08.430221Z","shell.execute_reply":"2024-11-24T16:54:26.495001Z"}},"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\nCollecting torchgeometry\n  Downloading torchgeometry-0.1.2-py2.py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torchgeometry) (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->torchgeometry) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->torchgeometry) (1.3.0)\nDownloading torchgeometry-0.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torchgeometry\nSuccessfully installed torchgeometry-0.1.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install segmentation-models-pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:54:28.113250Z","iopub.execute_input":"2024-11-24T16:54:28.113646Z","iopub.status.idle":"2024-11-24T16:54:41.574065Z","shell.execute_reply.started":"2024-11-24T16:54:28.113613Z","shell.execute_reply":"2024-11-24T16:54:41.572745Z"}},"outputs":[{"name":"stdout","text":"Collecting segmentation-models-pytorch\n  Downloading segmentation_models_pytorch-0.3.4-py3-none-any.whl.metadata (30 kB)\nCollecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: huggingface-hub>=0.24.6 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.25.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.3.0)\nCollecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (1.16.0)\nCollecting timm==0.9.7 (from segmentation-models-pytorch)\n  Downloading timm-0.9.7-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.19.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.4.0)\nCollecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (4.12.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\nDownloading segmentation_models_pytorch-0.3.4-py3-none-any.whl (109 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=e2a352f6bb833aa6e47e26be88975ec8c201e94f988d7ed3a9a5e7307273143b\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=d59cf7bda209f9fd9908629bef89958092b3c9aea2cf0df2f23bc36e1d2ff03d\n  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\nSuccessfully built efficientnet-pytorch pretrainedmodels\nInstalling collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.9\n    Uninstalling timm-1.0.9:\n      Successfully uninstalled timm-1.0.9\nSuccessfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.4 timm-0.9.7\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"pip install -U albumentations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:54:51.711007Z","iopub.execute_input":"2024-11-24T16:54:51.711316Z","iopub.status.idle":"2024-11-24T16:55:00.056355Z","shell.execute_reply.started":"2024-11-24T16:54:51.711266Z","shell.execute_reply":"2024-11-24T16:55:00.055273Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.4.21)\nRequirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.26.4)\nRequirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.14.1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.2)\nRequirement already satisfied: pydantic>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (2.9.2)\nRequirement already satisfied: albucore==0.0.20 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.0.20)\nRequirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.2.0)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.10.0.84)\nRequirement already satisfied: stringzilla>=3.10.4 in /opt/conda/lib/python3.10/site-packages (from albucore==0.0.20->albumentations) (3.10.10)\nRequirement already satisfied: simsimd>=5.9.2 in /opt/conda/lib/python3.10/site-packages (from albucore==0.0.20->albumentations) (6.1.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport segmentation_models_pytorch as smp\n\nimport cv2\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport time\nfrom PIL import Image\nimport os\n\nimport wandb\nfrom torchsummary import summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:55:18.508048Z","iopub.execute_input":"2024-11-24T16:55:18.508416Z","iopub.status.idle":"2024-11-24T16:55:26.464483Z","shell.execute_reply.started":"2024-11-24T16:55:18.508383Z","shell.execute_reply":"2024-11-24T16:55:26.463547Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(A.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:55:29.568968Z","iopub.execute_input":"2024-11-24T16:55:29.569334Z","iopub.status.idle":"2024-11-24T16:55:29.574077Z","shell.execute_reply.started":"2024-11-24T16:55:29.569276Z","shell.execute_reply":"2024-11-24T16:55:29.573193Z"}},"outputs":[{"name":"stdout","text":"1.4.21\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 6","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:55:34.653431Z","iopub.execute_input":"2024-11-24T16:55:34.654063Z","iopub.status.idle":"2024-11-24T16:55:34.657649Z","shell.execute_reply.started":"2024-11-24T16:55:34.654030Z","shell.execute_reply":"2024-11-24T16:55:34.656772Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"IMAGES_PATH = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\nMASKS_PATH =  \"/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt/\"\nTEST_PATH = \"/kaggle/input/bkai-igh-neopolyp/test/test/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:55:36.534235Z","iopub.execute_input":"2024-11-24T16:55:36.535059Z","iopub.status.idle":"2024-11-24T16:55:36.538897Z","shell.execute_reply.started":"2024-11-24T16:55:36.535026Z","shell.execute_reply":"2024-11-24T16:55:36.537905Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### transform","metadata":{}},{"cell_type":"code","source":"#transf with ImageNet statistics\ntransform = A.Compose([\n    A.Resize(height=256, width=256),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:59:15.318975Z","iopub.execute_input":"2024-11-24T16:59:15.319819Z","iopub.status.idle":"2024-11-24T16:59:15.327104Z","shell.execute_reply.started":"2024-11-24T16:59:15.319781Z","shell.execute_reply":"2024-11-24T16:59:15.326264Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"transform_2 = A.Compose([\n    A.Resize(height=256, width=256),\n    A.HorizontalFlip(p=0.4),\n    A.VerticalFlip(p=0.4),\n    A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:55:40.563226Z","iopub.execute_input":"2024-11-24T16:55:40.564244Z","iopub.status.idle":"2024-11-24T16:55:40.575836Z","shell.execute_reply.started":"2024-11-24T16:55:40.564193Z","shell.execute_reply":"2024-11-24T16:55:40.574905Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_76/2111000807.py:5: UserWarning: Argument 'eps' is not valid and will be ignored.\n  A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### Data","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, image_paths, mask_paths, resize = (256,256), transform=None):\n        self.image_paths = image_paths\n        self.mask_paths = mask_paths\n        self.resize = resize\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def read_mask(self, mask_path):\n        image = cv2.imread(mask_path)\n        image = cv2.resize(image, self.resize)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n        lower_red1 = np.array([0, 100, 20])\n        upper_red1 = np.array([10, 255, 255])\n        lower_red2 = np.array([160,100,20])\n        upper_red2 = np.array([179,255,255])\n        \n        lower_mask_red = cv2.inRange(image, lower_red1, upper_red1)\n        upper_mask_red = cv2.inRange(image, lower_red2, upper_red2)\n        \n        red_mask = lower_mask_red + upper_mask_red\n        red_mask[red_mask != 0] = 1\n\n        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n        green_mask[green_mask != 0] = 2\n\n        full_mask = cv2.bitwise_or(red_mask, green_mask)\n        full_mask = np.expand_dims(full_mask, axis=-1) \n        full_mask = full_mask.astype(np.uint8)\n        \n        return full_mask\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label_path = self.mask_paths[idx]\n        image = cv2.imread(img_path)  #  BGR\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert to RGB\n        label = self.read_mask(label_path)  \n        image = cv2.resize(image, self.resize)\n        if self.transform:\n            image = self.transform(image)\n            \n        return image, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:55:43.261715Z","iopub.execute_input":"2024-11-24T16:55:43.262324Z","iopub.status.idle":"2024-11-24T16:55:43.271842Z","shell.execute_reply.started":"2024-11-24T16:55:43.262269Z","shell.execute_reply":"2024-11-24T16:55:43.270997Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"image_paths = []\nfor root, dirs, files in os.walk(IMAGES_PATH):\n    for file in files:\n        path = os.path.join(root,file)\n        image_paths.append(path)\n        \nlen(image_paths)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:55:45.643833Z","iopub.execute_input":"2024-11-24T16:55:45.644603Z","iopub.status.idle":"2024-11-24T16:55:46.851043Z","shell.execute_reply.started":"2024-11-24T16:55:45.644569Z","shell.execute_reply":"2024-11-24T16:55:46.850119Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"mask_paths = []\nfor root, dirs, files in os.walk(MASKS_PATH):\n    for file in files:\n        path = os.path.join(root,file)\n        mask_paths.append(path)\n        \nlen(mask_paths)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:55:47.860162Z","iopub.execute_input":"2024-11-24T16:55:47.860870Z","iopub.status.idle":"2024-11-24T16:55:49.060613Z","shell.execute_reply.started":"2024-11-24T16:55:47.860834Z","shell.execute_reply":"2024-11-24T16:55:49.059730Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"init_dataset = CustomDataset(image_paths, mask_paths, transform = None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:55:50.451868Z","iopub.execute_input":"2024-11-24T16:55:50.452205Z","iopub.status.idle":"2024-11-24T16:55:50.456340Z","shell.execute_reply.started":"2024-11-24T16:55:50.452174Z","shell.execute_reply":"2024-11-24T16:55:50.455510Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(len(init_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:55:52.486116Z","iopub.execute_input":"2024-11-24T16:55:52.486768Z","iopub.status.idle":"2024-11-24T16:55:52.490993Z","shell.execute_reply.started":"2024-11-24T16:55:52.486733Z","shell.execute_reply":"2024-11-24T16:55:52.490189Z"}},"outputs":[{"name":"stdout","text":"1000\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"images_data = []\nlabels_data = []\nfor x,y in init_dataset:\n    images_data.append(x)\n    labels_data.append(y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:55:53.996981Z","iopub.execute_input":"2024-11-24T16:55:53.997326Z","iopub.status.idle":"2024-11-24T16:56:24.244330Z","shell.execute_reply.started":"2024-11-24T16:55:53.997283Z","shell.execute_reply":"2024-11-24T16:56:24.243200Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class ArgumentedDataSet(Dataset):\n    def __init__(self, data, targets, transform=None):\n        self.data = data\n        self.targets = targets\n        self.transform = transform\n\n    def __getitem__(self, index):\n        image = self.data[index]\n        label = self.targets[index]\n        assert image.shape[:2] == label.shape[:2]\n        if self.transform:\n            transformed = self.transform(image=image, mask=label)\n            image = transformed['image'].float()\n            label = transformed['mask'].float()\n            label = torch.squeeze(label, dim = 2)\n        return image, label\n    \n    def __len__(self):\n        return len(self.data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:19:49.795032Z","iopub.execute_input":"2024-11-24T17:19:49.795431Z","iopub.status.idle":"2024-11-24T17:19:49.803144Z","shell.execute_reply.started":"2024-11-24T17:19:49.795398Z","shell.execute_reply":"2024-11-24T17:19:49.802319Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"train_size = int(len(init_dataset) * 0.80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:19:52.816643Z","iopub.execute_input":"2024-11-24T17:19:52.817383Z","iopub.status.idle":"2024-11-24T17:19:52.822056Z","shell.execute_reply.started":"2024-11-24T17:19:52.817351Z","shell.execute_reply":"2024-11-24T17:19:52.821171Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:19:54.914217Z","iopub.execute_input":"2024-11-24T17:19:54.914626Z","iopub.status.idle":"2024-11-24T17:19:54.922498Z","shell.execute_reply.started":"2024-11-24T17:19:54.914593Z","shell.execute_reply":"2024-11-24T17:19:54.921584Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7ead11310d70>"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"train_set = ArgumentedDataSet(images_data[:train_size], labels_data[:train_size], transform=transform_2)\nvalid_set = ArgumentedDataSet(images_data[train_size:], labels_data[train_size:], transform=transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:19:56.557143Z","iopub.execute_input":"2024-11-24T17:19:56.557934Z","iopub.status.idle":"2024-11-24T17:19:56.562996Z","shell.execute_reply.started":"2024-11-24T17:19:56.557895Z","shell.execute_reply":"2024-11-24T17:19:56.562014Z"}},"outputs":[],"execution_count":57},{"cell_type":"markdown","source":"### Data Loader","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:19:59.009840Z","iopub.execute_input":"2024-11-24T17:19:59.010553Z","iopub.status.idle":"2024-11-24T17:19:59.015404Z","shell.execute_reply.started":"2024-11-24T17:19:59.010518Z","shell.execute_reply":"2024-11-24T17:19:59.014705Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"print(len(train_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:20:00.654990Z","iopub.execute_input":"2024-11-24T17:20:00.655663Z","iopub.status.idle":"2024-11-24T17:20:00.661107Z","shell.execute_reply.started":"2024-11-24T17:20:00.655626Z","shell.execute_reply":"2024-11-24T17:20:00.660320Z"}},"outputs":[{"name":"stdout","text":"134\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"for images, masks in train_loader:\n    print(f\"Image batch shape: {images.shape}\")  # Should be (B, 3, 256, 256)\n    print(f\"Mask batch shape: {masks.shape}\")    # Should be (B, 256, 256)\n    print(f\"Image dtype: {images.dtype}\")        # torch.float32\n    print(f\"Mask dtype: {masks.dtype}\")          # torch.int64\n    print(f\"Mask unique values: {torch.unique(masks)}\")  # Should show [0, 1, 2]\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:20:02.269805Z","iopub.execute_input":"2024-11-24T17:20:02.270478Z","iopub.status.idle":"2024-11-24T17:20:02.303887Z","shell.execute_reply.started":"2024-11-24T17:20:02.270437Z","shell.execute_reply":"2024-11-24T17:20:02.302936Z"}},"outputs":[{"name":"stdout","text":"Image batch shape: torch.Size([6, 3, 256, 256])\nMask batch shape: torch.Size([6, 256, 256])\nImage dtype: torch.float32\nMask dtype: torch.float32\nMask unique values: tensor([0., 1., 2.])\n","output_type":"stream"}],"execution_count":60},{"cell_type":"markdown","source":"# Hyperparameters","metadata":{}},{"cell_type":"code","source":"NUM_CLASSES = 3\nNUM_EPOCHS = 30\nLEARNING_RATE = 1e-4\n\nModel_PATH = '/kaggle/working/unet-model.pth'\n\nPreTrained_path = \"/kaggle/input/unet-checkpoint/unet-model.pth\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:20:08.027781Z","iopub.execute_input":"2024-11-24T17:20:08.028449Z","iopub.status.idle":"2024-11-24T17:20:08.033518Z","shell.execute_reply.started":"2024-11-24T17:20:08.028415Z","shell.execute_reply":"2024-11-24T17:20:08.032644Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nDEVICE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:20:10.061851Z","iopub.execute_input":"2024-11-24T17:20:10.062913Z","iopub.status.idle":"2024-11-24T17:20:10.069632Z","shell.execute_reply.started":"2024-11-24T17:20:10.062873Z","shell.execute_reply":"2024-11-24T17:20:10.068547Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":62},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"UNET = smp.UnetPlusPlus(\n    encoder_name=\"resnet50\",        \n    encoder_weights=\"imagenet\",      \n    in_channels=3, \n    classes= NUM_CLASSES,\n    #activation= 'softmax'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:20:11.579545Z","iopub.execute_input":"2024-11-24T17:20:11.580381Z","iopub.status.idle":"2024-11-24T17:20:12.499771Z","shell.execute_reply.started":"2024-11-24T17:20:11.580345Z","shell.execute_reply":"2024-11-24T17:20:12.498791Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"model = UNET.to(DEVICE)\nsummary(model, (3, 256, 256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:20:14.807177Z","iopub.execute_input":"2024-11-24T17:20:14.808054Z","iopub.status.idle":"2024-11-24T17:20:14.990819Z","shell.execute_reply.started":"2024-11-24T17:20:14.808016Z","shell.execute_reply":"2024-11-24T17:20:14.989940Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 128, 128]           9,408\n       BatchNorm2d-2         [-1, 64, 128, 128]             128\n              ReLU-3         [-1, 64, 128, 128]               0\n         MaxPool2d-4           [-1, 64, 64, 64]               0\n            Conv2d-5           [-1, 64, 64, 64]           4,096\n       BatchNorm2d-6           [-1, 64, 64, 64]             128\n              ReLU-7           [-1, 64, 64, 64]               0\n            Conv2d-8           [-1, 64, 64, 64]          36,864\n       BatchNorm2d-9           [-1, 64, 64, 64]             128\n             ReLU-10           [-1, 64, 64, 64]               0\n           Conv2d-11          [-1, 256, 64, 64]          16,384\n      BatchNorm2d-12          [-1, 256, 64, 64]             512\n           Conv2d-13          [-1, 256, 64, 64]          16,384\n      BatchNorm2d-14          [-1, 256, 64, 64]             512\n             ReLU-15          [-1, 256, 64, 64]               0\n       Bottleneck-16          [-1, 256, 64, 64]               0\n           Conv2d-17           [-1, 64, 64, 64]          16,384\n      BatchNorm2d-18           [-1, 64, 64, 64]             128\n             ReLU-19           [-1, 64, 64, 64]               0\n           Conv2d-20           [-1, 64, 64, 64]          36,864\n      BatchNorm2d-21           [-1, 64, 64, 64]             128\n             ReLU-22           [-1, 64, 64, 64]               0\n           Conv2d-23          [-1, 256, 64, 64]          16,384\n      BatchNorm2d-24          [-1, 256, 64, 64]             512\n             ReLU-25          [-1, 256, 64, 64]               0\n       Bottleneck-26          [-1, 256, 64, 64]               0\n           Conv2d-27           [-1, 64, 64, 64]          16,384\n      BatchNorm2d-28           [-1, 64, 64, 64]             128\n             ReLU-29           [-1, 64, 64, 64]               0\n           Conv2d-30           [-1, 64, 64, 64]          36,864\n      BatchNorm2d-31           [-1, 64, 64, 64]             128\n             ReLU-32           [-1, 64, 64, 64]               0\n           Conv2d-33          [-1, 256, 64, 64]          16,384\n      BatchNorm2d-34          [-1, 256, 64, 64]             512\n             ReLU-35          [-1, 256, 64, 64]               0\n       Bottleneck-36          [-1, 256, 64, 64]               0\n           Conv2d-37          [-1, 128, 64, 64]          32,768\n      BatchNorm2d-38          [-1, 128, 64, 64]             256\n             ReLU-39          [-1, 128, 64, 64]               0\n           Conv2d-40          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-41          [-1, 128, 32, 32]             256\n             ReLU-42          [-1, 128, 32, 32]               0\n           Conv2d-43          [-1, 512, 32, 32]          65,536\n      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n           Conv2d-45          [-1, 512, 32, 32]         131,072\n      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n             ReLU-47          [-1, 512, 32, 32]               0\n       Bottleneck-48          [-1, 512, 32, 32]               0\n           Conv2d-49          [-1, 128, 32, 32]          65,536\n      BatchNorm2d-50          [-1, 128, 32, 32]             256\n             ReLU-51          [-1, 128, 32, 32]               0\n           Conv2d-52          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-53          [-1, 128, 32, 32]             256\n             ReLU-54          [-1, 128, 32, 32]               0\n           Conv2d-55          [-1, 512, 32, 32]          65,536\n      BatchNorm2d-56          [-1, 512, 32, 32]           1,024\n             ReLU-57          [-1, 512, 32, 32]               0\n       Bottleneck-58          [-1, 512, 32, 32]               0\n           Conv2d-59          [-1, 128, 32, 32]          65,536\n      BatchNorm2d-60          [-1, 128, 32, 32]             256\n             ReLU-61          [-1, 128, 32, 32]               0\n           Conv2d-62          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-63          [-1, 128, 32, 32]             256\n             ReLU-64          [-1, 128, 32, 32]               0\n           Conv2d-65          [-1, 512, 32, 32]          65,536\n      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n             ReLU-67          [-1, 512, 32, 32]               0\n       Bottleneck-68          [-1, 512, 32, 32]               0\n           Conv2d-69          [-1, 128, 32, 32]          65,536\n      BatchNorm2d-70          [-1, 128, 32, 32]             256\n             ReLU-71          [-1, 128, 32, 32]               0\n           Conv2d-72          [-1, 128, 32, 32]         147,456\n      BatchNorm2d-73          [-1, 128, 32, 32]             256\n             ReLU-74          [-1, 128, 32, 32]               0\n           Conv2d-75          [-1, 512, 32, 32]          65,536\n      BatchNorm2d-76          [-1, 512, 32, 32]           1,024\n             ReLU-77          [-1, 512, 32, 32]               0\n       Bottleneck-78          [-1, 512, 32, 32]               0\n           Conv2d-79          [-1, 256, 32, 32]         131,072\n      BatchNorm2d-80          [-1, 256, 32, 32]             512\n             ReLU-81          [-1, 256, 32, 32]               0\n           Conv2d-82          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-83          [-1, 256, 16, 16]             512\n             ReLU-84          [-1, 256, 16, 16]               0\n           Conv2d-85         [-1, 1024, 16, 16]         262,144\n      BatchNorm2d-86         [-1, 1024, 16, 16]           2,048\n           Conv2d-87         [-1, 1024, 16, 16]         524,288\n      BatchNorm2d-88         [-1, 1024, 16, 16]           2,048\n             ReLU-89         [-1, 1024, 16, 16]               0\n       Bottleneck-90         [-1, 1024, 16, 16]               0\n           Conv2d-91          [-1, 256, 16, 16]         262,144\n      BatchNorm2d-92          [-1, 256, 16, 16]             512\n             ReLU-93          [-1, 256, 16, 16]               0\n           Conv2d-94          [-1, 256, 16, 16]         589,824\n      BatchNorm2d-95          [-1, 256, 16, 16]             512\n             ReLU-96          [-1, 256, 16, 16]               0\n           Conv2d-97         [-1, 1024, 16, 16]         262,144\n      BatchNorm2d-98         [-1, 1024, 16, 16]           2,048\n             ReLU-99         [-1, 1024, 16, 16]               0\n      Bottleneck-100         [-1, 1024, 16, 16]               0\n          Conv2d-101          [-1, 256, 16, 16]         262,144\n     BatchNorm2d-102          [-1, 256, 16, 16]             512\n            ReLU-103          [-1, 256, 16, 16]               0\n          Conv2d-104          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-105          [-1, 256, 16, 16]             512\n            ReLU-106          [-1, 256, 16, 16]               0\n          Conv2d-107         [-1, 1024, 16, 16]         262,144\n     BatchNorm2d-108         [-1, 1024, 16, 16]           2,048\n            ReLU-109         [-1, 1024, 16, 16]               0\n      Bottleneck-110         [-1, 1024, 16, 16]               0\n          Conv2d-111          [-1, 256, 16, 16]         262,144\n     BatchNorm2d-112          [-1, 256, 16, 16]             512\n            ReLU-113          [-1, 256, 16, 16]               0\n          Conv2d-114          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-115          [-1, 256, 16, 16]             512\n            ReLU-116          [-1, 256, 16, 16]               0\n          Conv2d-117         [-1, 1024, 16, 16]         262,144\n     BatchNorm2d-118         [-1, 1024, 16, 16]           2,048\n            ReLU-119         [-1, 1024, 16, 16]               0\n      Bottleneck-120         [-1, 1024, 16, 16]               0\n          Conv2d-121          [-1, 256, 16, 16]         262,144\n     BatchNorm2d-122          [-1, 256, 16, 16]             512\n            ReLU-123          [-1, 256, 16, 16]               0\n          Conv2d-124          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-125          [-1, 256, 16, 16]             512\n            ReLU-126          [-1, 256, 16, 16]               0\n          Conv2d-127         [-1, 1024, 16, 16]         262,144\n     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n            ReLU-129         [-1, 1024, 16, 16]               0\n      Bottleneck-130         [-1, 1024, 16, 16]               0\n          Conv2d-131          [-1, 256, 16, 16]         262,144\n     BatchNorm2d-132          [-1, 256, 16, 16]             512\n            ReLU-133          [-1, 256, 16, 16]               0\n          Conv2d-134          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-135          [-1, 256, 16, 16]             512\n            ReLU-136          [-1, 256, 16, 16]               0\n          Conv2d-137         [-1, 1024, 16, 16]         262,144\n     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n            ReLU-139         [-1, 1024, 16, 16]               0\n      Bottleneck-140         [-1, 1024, 16, 16]               0\n          Conv2d-141          [-1, 512, 16, 16]         524,288\n     BatchNorm2d-142          [-1, 512, 16, 16]           1,024\n            ReLU-143          [-1, 512, 16, 16]               0\n          Conv2d-144            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-145            [-1, 512, 8, 8]           1,024\n            ReLU-146            [-1, 512, 8, 8]               0\n          Conv2d-147           [-1, 2048, 8, 8]       1,048,576\n     BatchNorm2d-148           [-1, 2048, 8, 8]           4,096\n          Conv2d-149           [-1, 2048, 8, 8]       2,097,152\n     BatchNorm2d-150           [-1, 2048, 8, 8]           4,096\n            ReLU-151           [-1, 2048, 8, 8]               0\n      Bottleneck-152           [-1, 2048, 8, 8]               0\n          Conv2d-153            [-1, 512, 8, 8]       1,048,576\n     BatchNorm2d-154            [-1, 512, 8, 8]           1,024\n            ReLU-155            [-1, 512, 8, 8]               0\n          Conv2d-156            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-157            [-1, 512, 8, 8]           1,024\n            ReLU-158            [-1, 512, 8, 8]               0\n          Conv2d-159           [-1, 2048, 8, 8]       1,048,576\n     BatchNorm2d-160           [-1, 2048, 8, 8]           4,096\n            ReLU-161           [-1, 2048, 8, 8]               0\n      Bottleneck-162           [-1, 2048, 8, 8]               0\n          Conv2d-163            [-1, 512, 8, 8]       1,048,576\n     BatchNorm2d-164            [-1, 512, 8, 8]           1,024\n            ReLU-165            [-1, 512, 8, 8]               0\n          Conv2d-166            [-1, 512, 8, 8]       2,359,296\n     BatchNorm2d-167            [-1, 512, 8, 8]           1,024\n            ReLU-168            [-1, 512, 8, 8]               0\n          Conv2d-169           [-1, 2048, 8, 8]       1,048,576\n     BatchNorm2d-170           [-1, 2048, 8, 8]           4,096\n            ReLU-171           [-1, 2048, 8, 8]               0\n      Bottleneck-172           [-1, 2048, 8, 8]               0\n   ResNetEncoder-173  [[-1, 3, 256, 256], [-1, 64, 128, 128], [-1, 256, 64, 64], [-1, 512, 32, 32], [-1, 1024, 16, 16], [-1, 2048, 8, 8]]               0\n        Identity-174         [-1, 3072, 16, 16]               0\n       Attention-175         [-1, 3072, 16, 16]               0\n          Conv2d-176          [-1, 256, 16, 16]       7,077,888\n     BatchNorm2d-177          [-1, 256, 16, 16]             512\n            ReLU-178          [-1, 256, 16, 16]               0\n          Conv2d-179          [-1, 256, 16, 16]         589,824\n     BatchNorm2d-180          [-1, 256, 16, 16]             512\n            ReLU-181          [-1, 256, 16, 16]               0\n        Identity-182          [-1, 256, 16, 16]               0\n       Attention-183          [-1, 256, 16, 16]               0\n    DecoderBlock-184          [-1, 256, 16, 16]               0\n        Identity-185         [-1, 1536, 32, 32]               0\n       Attention-186         [-1, 1536, 32, 32]               0\n          Conv2d-187          [-1, 512, 32, 32]       7,077,888\n     BatchNorm2d-188          [-1, 512, 32, 32]           1,024\n            ReLU-189          [-1, 512, 32, 32]               0\n          Conv2d-190          [-1, 512, 32, 32]       2,359,296\n     BatchNorm2d-191          [-1, 512, 32, 32]           1,024\n            ReLU-192          [-1, 512, 32, 32]               0\n        Identity-193          [-1, 512, 32, 32]               0\n       Attention-194          [-1, 512, 32, 32]               0\n    DecoderBlock-195          [-1, 512, 32, 32]               0\n        Identity-196          [-1, 768, 64, 64]               0\n       Attention-197          [-1, 768, 64, 64]               0\n          Conv2d-198          [-1, 256, 64, 64]       1,769,472\n     BatchNorm2d-199          [-1, 256, 64, 64]             512\n            ReLU-200          [-1, 256, 64, 64]               0\n          Conv2d-201          [-1, 256, 64, 64]         589,824\n     BatchNorm2d-202          [-1, 256, 64, 64]             512\n            ReLU-203          [-1, 256, 64, 64]               0\n        Identity-204          [-1, 256, 64, 64]               0\n       Attention-205          [-1, 256, 64, 64]               0\n    DecoderBlock-206          [-1, 256, 64, 64]               0\n        Identity-207        [-1, 320, 128, 128]               0\n       Attention-208        [-1, 320, 128, 128]               0\n          Conv2d-209         [-1, 64, 128, 128]         184,320\n     BatchNorm2d-210         [-1, 64, 128, 128]             128\n            ReLU-211         [-1, 64, 128, 128]               0\n          Conv2d-212         [-1, 64, 128, 128]          36,864\n     BatchNorm2d-213         [-1, 64, 128, 128]             128\n            ReLU-214         [-1, 64, 128, 128]               0\n        Identity-215         [-1, 64, 128, 128]               0\n       Attention-216         [-1, 64, 128, 128]               0\n    DecoderBlock-217         [-1, 64, 128, 128]               0\n        Identity-218         [-1, 1280, 32, 32]               0\n       Attention-219         [-1, 1280, 32, 32]               0\n          Conv2d-220          [-1, 128, 32, 32]       1,474,560\n     BatchNorm2d-221          [-1, 128, 32, 32]             256\n            ReLU-222          [-1, 128, 32, 32]               0\n          Conv2d-223          [-1, 128, 32, 32]         147,456\n     BatchNorm2d-224          [-1, 128, 32, 32]             256\n            ReLU-225          [-1, 128, 32, 32]               0\n        Identity-226          [-1, 128, 32, 32]               0\n       Attention-227          [-1, 128, 32, 32]               0\n    DecoderBlock-228          [-1, 128, 32, 32]               0\n        Identity-229         [-1, 1024, 64, 64]               0\n       Attention-230         [-1, 1024, 64, 64]               0\n          Conv2d-231          [-1, 256, 64, 64]       2,359,296\n     BatchNorm2d-232          [-1, 256, 64, 64]             512\n            ReLU-233          [-1, 256, 64, 64]               0\n          Conv2d-234          [-1, 256, 64, 64]         589,824\n     BatchNorm2d-235          [-1, 256, 64, 64]             512\n            ReLU-236          [-1, 256, 64, 64]               0\n        Identity-237          [-1, 256, 64, 64]               0\n       Attention-238          [-1, 256, 64, 64]               0\n    DecoderBlock-239          [-1, 256, 64, 64]               0\n        Identity-240        [-1, 384, 128, 128]               0\n       Attention-241        [-1, 384, 128, 128]               0\n          Conv2d-242         [-1, 64, 128, 128]         221,184\n     BatchNorm2d-243         [-1, 64, 128, 128]             128\n            ReLU-244         [-1, 64, 128, 128]               0\n          Conv2d-245         [-1, 64, 128, 128]          36,864\n     BatchNorm2d-246         [-1, 64, 128, 128]             128\n            ReLU-247         [-1, 64, 128, 128]               0\n        Identity-248         [-1, 64, 128, 128]               0\n       Attention-249         [-1, 64, 128, 128]               0\n    DecoderBlock-250         [-1, 64, 128, 128]               0\n        Identity-251          [-1, 896, 64, 64]               0\n       Attention-252          [-1, 896, 64, 64]               0\n          Conv2d-253           [-1, 64, 64, 64]         516,096\n     BatchNorm2d-254           [-1, 64, 64, 64]             128\n            ReLU-255           [-1, 64, 64, 64]               0\n          Conv2d-256           [-1, 64, 64, 64]          36,864\n     BatchNorm2d-257           [-1, 64, 64, 64]             128\n            ReLU-258           [-1, 64, 64, 64]               0\n        Identity-259           [-1, 64, 64, 64]               0\n       Attention-260           [-1, 64, 64, 64]               0\n    DecoderBlock-261           [-1, 64, 64, 64]               0\n        Identity-262        [-1, 448, 128, 128]               0\n       Attention-263        [-1, 448, 128, 128]               0\n          Conv2d-264         [-1, 64, 128, 128]         258,048\n     BatchNorm2d-265         [-1, 64, 128, 128]             128\n            ReLU-266         [-1, 64, 128, 128]               0\n          Conv2d-267         [-1, 64, 128, 128]          36,864\n     BatchNorm2d-268         [-1, 64, 128, 128]             128\n            ReLU-269         [-1, 64, 128, 128]               0\n        Identity-270         [-1, 64, 128, 128]               0\n       Attention-271         [-1, 64, 128, 128]               0\n    DecoderBlock-272         [-1, 64, 128, 128]               0\n        Identity-273        [-1, 320, 128, 128]               0\n       Attention-274        [-1, 320, 128, 128]               0\n          Conv2d-275         [-1, 32, 128, 128]          92,160\n     BatchNorm2d-276         [-1, 32, 128, 128]              64\n            ReLU-277         [-1, 32, 128, 128]               0\n          Conv2d-278         [-1, 32, 128, 128]           9,216\n     BatchNorm2d-279         [-1, 32, 128, 128]              64\n            ReLU-280         [-1, 32, 128, 128]               0\n        Identity-281         [-1, 32, 128, 128]               0\n       Attention-282         [-1, 32, 128, 128]               0\n    DecoderBlock-283         [-1, 32, 128, 128]               0\n          Conv2d-284         [-1, 16, 256, 256]           4,608\n     BatchNorm2d-285         [-1, 16, 256, 256]              32\n            ReLU-286         [-1, 16, 256, 256]               0\n          Conv2d-287         [-1, 16, 256, 256]           2,304\n     BatchNorm2d-288         [-1, 16, 256, 256]              32\n            ReLU-289         [-1, 16, 256, 256]               0\n        Identity-290         [-1, 16, 256, 256]               0\n       Attention-291         [-1, 16, 256, 256]               0\n    DecoderBlock-292         [-1, 16, 256, 256]               0\nUnetPlusPlusDecoder-293         [-1, 16, 256, 256]               0\n          Conv2d-294          [-1, 3, 256, 256]             435\n        Identity-295          [-1, 3, 256, 256]               0\n        Identity-296          [-1, 3, 256, 256]               0\n      Activation-297          [-1, 3, 256, 256]               0\n================================================================\nTotal params: 48,986,035\nTrainable params: 48,986,035\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.75\nForward/backward pass size (MB): 1515.75\nParams size (MB): 186.87\nEstimated Total Size (MB): 1703.37\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"def initialize_weights(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n        if m.bias is not None:\n            nn.init.constant_(m.bias, 0)\n\n    elif isinstance(m, nn.BatchNorm2d):\n        nn.init.constant_(m.weight, 1)\n        nn.init.constant_(m.bias, 0)\n\n# Apply the initialization function to the model\nmodel.decoder.apply(initialize_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:20:20.521725Z","iopub.execute_input":"2024-11-24T17:20:20.522040Z","iopub.status.idle":"2024-11-24T17:20:20.534003Z","shell.execute_reply.started":"2024-11-24T17:20:20.522014Z","shell.execute_reply":"2024-11-24T17:20:20.533175Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"UnetPlusPlusDecoder(\n  (center): Identity()\n  (blocks): ModuleDict(\n    (x_0_0): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_0_1): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(1280, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_1_1): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_0_2): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(896, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_1_2): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_2_2): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_0_3): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_1_3): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_2_3): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_3_3): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n    (x_0_4): DecoderBlock(\n      (conv1): Conv2dReLU(\n        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention1): Attention(\n        (attention): Identity()\n      )\n      (conv2): Conv2dReLU(\n        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n      (attention2): Attention(\n        (attention): Identity()\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":65},{"cell_type":"markdown","source":"# Wandb para","metadata":{}},{"cell_type":"code","source":"PROJECT = \"BKAI-IGH NeoPolyp\"\nRESUME = \"allow\"\nWANDB_KEY = \"d9d14819dddd8a35a353b5c0b087e0f60d717140\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:20:24.525086Z","iopub.execute_input":"2024-11-24T17:20:24.525452Z","iopub.status.idle":"2024-11-24T17:20:24.530601Z","shell.execute_reply.started":"2024-11-24T17:20:24.525420Z","shell.execute_reply":"2024-11-24T17:20:24.529700Z"}},"outputs":[],"execution_count":66},{"cell_type":"markdown","source":"# Set up","metadata":{}},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:20:26.918212Z","iopub.execute_input":"2024-11-24T17:20:26.918936Z","iopub.status.idle":"2024-11-24T17:20:26.924702Z","shell.execute_reply.started":"2024-11-24T17:20:26.918899Z","shell.execute_reply":"2024-11-24T17:20:26.924025Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"wandb.login(\n    key = \"d9d14819dddd8a35a353b5c0b087e0f60d717140\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:57:02.999180Z","iopub.execute_input":"2024-11-24T16:57:02.999554Z","iopub.status.idle":"2024-11-24T16:57:04.389552Z","shell.execute_reply.started":"2024-11-24T16:57:02.999523Z","shell.execute_reply":"2024-11-24T16:57:04.388448Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"wandb.init(\n    project=PROJECT,\n    resume=RESUME,\n    name=\"init_model\",\n    config={\n        \"learning_rate\": LEARNING_RATE,\n        \"epochs\": NUM_EPOCHS,\n        \"batch_size\": BATCH_SIZE,\n        \"weight_initialization\": \"ImageNet\",\n    },\n)\nwandb.watch(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T18:32:15.948773Z","iopub.execute_input":"2024-11-24T18:32:15.949155Z","iopub.status.idle":"2024-11-24T18:32:19.431601Z","shell.execute_reply.started":"2024-11-24T18:32:15.949109Z","shell.execute_reply":"2024-11-24T18:32:19.430873Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:2bbsxdyb) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.393 MB of 0.393 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3272a4f80014432591e829fc81ed523f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Dice_Coefficient</td><td>▁▃▅▆█</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▅▃▂▁</td></tr><tr><td>val_loss</td><td>██▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Dice_Coefficient</td><td>1.00887</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>train_loss</td><td>0.04656</td></tr><tr><td>val_loss</td><td>0.06205</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">init_model</strong> at: <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/2bbsxdyb' target=\"_blank\">https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/2bbsxdyb</a><br/> View project at: <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp' target=\"_blank\">https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241124_172030-2bbsxdyb/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:2bbsxdyb). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241124_183215-mf8azne4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/mf8azne4' target=\"_blank\">init_model</a></strong> to <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp' target=\"_blank\">https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/mf8azne4' target=\"_blank\">https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/mf8azne4</a>"},"metadata":{}},{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}],"execution_count":81},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def dice_coefficient(pred, target, num_classes=3):\n    \"\"\"\n    Calculate the Dice coefficient for multi-class segmentation.\n    \n    Arguments:\n    pred -- Tensor of predicted class labels, shape: [batch_size, height, width]\n    target -- Tensor of ground truth class labels, shape: [batch_size, height, width]\n    num_classes -- Number of classes (including background), default 3 (background, polyp1, polyp2)\n\n    Returns:\n    dice -- Tensor with Dice coefficient for each class, shape: [num_classes]\n    \"\"\"\n    dice = torch.zeros(num_classes).to(pred.device)\n\n    for c in range(num_classes):\n        # Create masks for the current class\n        pred_c = (pred == c).float()\n        target_c = (target == c).float()\n\n        # Compute intersection and sum of pixels for Dice coefficient\n        intersection = torch.sum(pred_c * target_c)\n        union = torch.sum(pred_c) + torch.sum(target_c)\n\n        # Avoid division by zero by adding a small constant (epsilon)\n        dice[c] = 2 * intersection / (union + 1e-6)\n\n    return dice.mean()  # Mean Dice score over all classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T18:37:38.905504Z","iopub.execute_input":"2024-11-24T18:37:38.905865Z","iopub.status.idle":"2024-11-24T18:37:38.912438Z","shell.execute_reply.started":"2024-11-24T18:37:38.905834Z","shell.execute_reply":"2024-11-24T18:37:38.911733Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"best_val_loss = float('inf')\n\ndef train_epoch(model, dataloader, optimizer, loss_fn, DEVICE):\n    \n    model.train()\n    running_loss = 0.0\n    for images, masks in dataloader:\n        images, masks = images.to(DEVICE), masks.to(DEVICE)\n        masks = masks.squeeze(dim=1).long()\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(images)\n\n        loss = loss_fn(outputs, masks)  # Ensure masks are float and add channel dimension\n\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    epoch_loss = running_loss / len(dataloader) \n    \n    return epoch_loss\n\ndef validate_epoch(model, dataloader, loss_fn, DEVICE):\n    model.eval()\n    total_dice = 0.0\n    running_loss = 0.0\n    with torch.no_grad():\n        for images, masks in dataloader:\n            images, masks = images.to(DEVICE), masks.to(DEVICE)\n            masks = masks.squeeze(dim=1).long()\n            \n            # Forward pass\n            outputs = model(images)\n            # Apply softmax along the class dimension (dim=1)\n            output_probabilities = F.softmax(outputs, dim=1)\n            \n            # To get the final predicted class for each pixel, you can use argmax\n            predicted_classes = torch.argmax(output_probabilities, dim=1)\n\n            # Compute loss\n            loss = loss_fn(outputs, masks)\n            running_loss += loss.item()\n\n            # Calculate Dice coefficient\n            dice = dice_coefficient(predicted_classes, masks)\n            total_dice += dice.item()\n\n    epoch_loss = running_loss / len(dataloader)\n    mean_dice = total_dice / len(dataloader)\n    return [epoch_loss, mean_dice]\n\n\n\nfor epoch in range(NUM_EPOCHS):\n    start_time = time.time()\n    \n    train_loss = train_epoch(model, train_loader, optimizer, loss_fn, DEVICE)\n    val_loss, val_dice = validate_epoch(model, val_loader, loss_fn, DEVICE)\n    \n    epoch_time = time.time() - start_time\n    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Time: {epoch_time:.2f}s, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Dice_Coefficient: {val_dice:.4f}\")\n\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), Model_PATH)\n        print(f\"New best checkpoint saved with val_loss: {val_loss:.4f}\")\n\n    # Log results to WandB\n    wandb.log({\n        \"epoch\": epoch,\n        \"train_loss\": train_loss,\n        \"val_loss\": val_loss,\n        \"Dice_Coefficient\": val_dice,\n    })\n\nwandb.finish()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T18:39:18.228308Z","iopub.execute_input":"2024-11-24T18:39:18.228651Z","iopub.status.idle":"2024-11-24T19:13:26.739562Z","shell.execute_reply.started":"2024-11-24T18:39:18.228619Z","shell.execute_reply":"2024-11-24T19:13:26.738908Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30, Time: 68.53s, Train Loss: 0.0319, Validation Loss: 0.0555, Dice_Coefficient: 0.7559\nNew best checkpoint saved with val_loss: 0.0555\nEpoch 2/30, Time: 67.93s, Train Loss: 0.0299, Validation Loss: 0.0572, Dice_Coefficient: 0.7607\nEpoch 3/30, Time: 68.02s, Train Loss: 0.0264, Validation Loss: 0.0553, Dice_Coefficient: 0.7391\nNew best checkpoint saved with val_loss: 0.0553\nEpoch 4/30, Time: 68.44s, Train Loss: 0.0299, Validation Loss: 0.0712, Dice_Coefficient: 0.6336\nEpoch 5/30, Time: 68.07s, Train Loss: 0.0292, Validation Loss: 0.0546, Dice_Coefficient: 0.7210\nNew best checkpoint saved with val_loss: 0.0546\nEpoch 6/30, Time: 68.24s, Train Loss: 0.0229, Validation Loss: 0.0558, Dice_Coefficient: 0.7373\nEpoch 7/30, Time: 68.30s, Train Loss: 0.0238, Validation Loss: 0.0548, Dice_Coefficient: 0.7333\nEpoch 8/30, Time: 68.15s, Train Loss: 0.0281, Validation Loss: 0.0668, Dice_Coefficient: 0.7455\nEpoch 9/30, Time: 67.97s, Train Loss: 0.0208, Validation Loss: 0.0567, Dice_Coefficient: 0.7488\nEpoch 10/30, Time: 67.97s, Train Loss: 0.0185, Validation Loss: 0.0611, Dice_Coefficient: 0.7472\nEpoch 11/30, Time: 67.90s, Train Loss: 0.0215, Validation Loss: 0.0589, Dice_Coefficient: 0.7457\nEpoch 12/30, Time: 68.36s, Train Loss: 0.0189, Validation Loss: 0.0602, Dice_Coefficient: 0.7220\nEpoch 13/30, Time: 68.12s, Train Loss: 0.0179, Validation Loss: 0.0523, Dice_Coefficient: 0.7625\nNew best checkpoint saved with val_loss: 0.0523\nEpoch 14/30, Time: 68.22s, Train Loss: 0.0144, Validation Loss: 0.0527, Dice_Coefficient: 0.7504\nEpoch 15/30, Time: 68.03s, Train Loss: 0.0187, Validation Loss: 0.0739, Dice_Coefficient: 0.7198\nEpoch 16/30, Time: 68.03s, Train Loss: 0.0198, Validation Loss: 0.0581, Dice_Coefficient: 0.7278\nEpoch 17/30, Time: 67.96s, Train Loss: 0.0181, Validation Loss: 0.0601, Dice_Coefficient: 0.7271\nEpoch 18/30, Time: 68.17s, Train Loss: 0.0201, Validation Loss: 0.0654, Dice_Coefficient: 0.7423\nEpoch 19/30, Time: 68.06s, Train Loss: 0.0152, Validation Loss: 0.0625, Dice_Coefficient: 0.7891\nEpoch 20/30, Time: 68.14s, Train Loss: 0.0134, Validation Loss: 0.0573, Dice_Coefficient: 0.7441\nEpoch 21/30, Time: 68.30s, Train Loss: 0.0111, Validation Loss: 0.0675, Dice_Coefficient: 0.7473\nEpoch 22/30, Time: 67.93s, Train Loss: 0.0131, Validation Loss: 0.0600, Dice_Coefficient: 0.7367\nEpoch 23/30, Time: 68.06s, Train Loss: 0.0118, Validation Loss: 0.0632, Dice_Coefficient: 0.7313\nEpoch 24/30, Time: 68.21s, Train Loss: 0.0122, Validation Loss: 0.0585, Dice_Coefficient: 0.7774\nEpoch 25/30, Time: 68.25s, Train Loss: 0.0103, Validation Loss: 0.0618, Dice_Coefficient: 0.7725\nEpoch 26/30, Time: 68.19s, Train Loss: 0.0113, Validation Loss: 0.0547, Dice_Coefficient: 0.7636\nEpoch 27/30, Time: 68.37s, Train Loss: 0.0102, Validation Loss: 0.0644, Dice_Coefficient: 0.7626\nEpoch 28/30, Time: 68.39s, Train Loss: 0.0108, Validation Loss: 0.0672, Dice_Coefficient: 0.7228\nEpoch 29/30, Time: 68.23s, Train Loss: 0.0107, Validation Loss: 0.0648, Dice_Coefficient: 0.7507\nEpoch 30/30, Time: 68.25s, Train Loss: 0.0106, Validation Loss: 0.0682, Dice_Coefficient: 0.7417\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.769 MB of 0.769 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35f33b7cc87f49089ee5aa6f9a4221f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Dice_Coefficient</td><td>▇▇▆▁▅▆▅▆▆▆▆▅▇▆▅▅▅▆█▆▆▆▅▇▇▇▇▅▆▆</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▇▆▇▇▅▅▇▄▄▅▄▃▂▄▄▄▄▃▂▁▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▂▃▂▇▂▂▂▆▂▄▃▄▁▁█▃▄▅▄▃▆▃▅▃▄▂▅▆▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Dice_Coefficient</td><td>0.74166</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>train_loss</td><td>0.01065</td></tr><tr><td>val_loss</td><td>0.06816</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">init_model</strong> at: <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/mf8azne4' target=\"_blank\">https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp/runs/mf8azne4</a><br/> View project at: <a href='https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp' target=\"_blank\">https://wandb.ai/tr-hoanganh1124-hanoi-university-of-science-and-technology/BKAI-IGH%20NeoPolyp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241124_183215-mf8azne4/logs</code>"},"metadata":{}}],"execution_count":86},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load(Model_PATH))\nmodel = model.to(DEVICE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TestData(Dataset):\n    def __init__(self, images_path, transform):\n\n        self.image_paths = image_paths\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n        \n    def __getitem__(self, index):\n        img_path = self.image_paths[index]\n        data = Image.open(img_path)\n        h = data.size[1]\n        w = data.size[0]\n        data = self.transform(data) / 255        \n        return data, img_path, h, w\n    \n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_image_paths = []\nfor root, dirs, files in os.walk(TEST_PATH):\n    for file in files:\n        path = os.path.join(root,file)\n        test_image_paths.append(path)\n        \nlen(test_image_paths)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tset_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = TestData(test_image_paths, transform)\ntest_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i, (data, path, h, w) in enumerate(test_dataloader):\n    img = data.to(DEVICE)  # Ensure img is on the correct device\n    break\n\nfig, arr = plt.subplots(5, 2, figsize=(16, 12))\narr[0][0].set_title('Image')\narr[0][1].set_title('Predict')\n\nmodel.eval()\nwith torch.no_grad():\n    predict = model(img)  # Get predictions\n\n# Optional: Denormalize the input image if needed\nmean = torch.tensor([0.485, 0.456, 0.406]).to(DEVICE)  # Adjust for your dataset\nstd = torch.tensor([0.229, 0.224, 0.225]).to(DEVICE)\nimg_vis = img * std[None, :, None, None] + mean[None, :, None, None]\nimg_vis = img_vis.clamp(0, 1)\n\nfor i in range(5):\n    # Show input image\n    arr[i][0].imshow(img_vis[i].cpu().permute(1, 2, 0).numpy())\n\n    # Process and visualize prediction\n    pred_mask = torch.argmax(predict[i], dim=0).cpu().numpy()\n    pred_resized = cv2.resize(pred_mask, (w[i].item(), h[i].item()), interpolation=cv2.INTER_NEAREST)\n    arr[i][1].imshow(pred_resized, cmap=\"nipy_spectral\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\nif not os.path.isdir(\"/kaggle/working/predicted_masks\"):\n    os.mkdir(\"/kaggle/working/predicted_masks\")\nfor _, (img, path, H, W) in enumerate(test_dataloader):\n    a = path\n    b = img\n    h = H\n    w = W\n    \n    with torch.no_grad():\n        predicted_mask = model(b)\n    for i in range(len(a)):\n        image_id = a[i].split('/')[-1].split('.')[0]\n        filename = image_id + \".png\"\n        mask2img = Resize((h[i].item(), w[i].item()), interpolation=InterpolationMode.NEAREST)(ToPILImage()(F.one_hot(torch.argmax(predicted_mask[i], 0)).permute(2, 0, 1).float()))\n        mask2img.save(os.path.join(\"/kaggle/working/predicted_masks/\", filename))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport os\n\ndef rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\ndef rle_encode_one_mask(mask):\n    pixels = mask.flatten()\n    pixels[pixels > 0] = 255\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    \n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    return rle_to_string(rle)\n\ndef rle2mask(mask_rle, shape=(3,3)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\n\ndef mask2string(dir):\n    ## mask --> string\n    strings = []\n    ids = []\n    ws, hs = [[] for i in range(2)]\n    for image_id in os.listdir(dir):\n        id = image_id.split('.')[0]\n        path = os.path.join(dir, image_id)\n        print(path)\n        img = cv2.imread(path)[:,:,::-1]\n        h, w = img.shape[0], img.shape[1]\n        for channel in range(2):\n            ws.append(w)\n            hs.append(h)\n            ids.append(f'{id}_{channel}')\n            string = rle_encode_one_mask(img[:,:,channel])\n            strings.append(string)\n    r = {\n        'ids': ids,\n        'strings': strings,\n    }\n    return r\n\n\nMASK_DIR_PATH = '/kaggle/working/predicted_masks' # change this to the path to your output mask folder\ndir = MASK_DIR_PATH\nres = mask2string(dir)\ndf = pd.DataFrame(columns=['Id', 'Expected'])\ndf['Id'] = res['ids']\ndf['Expected'] = res['strings']\n\ndf.to_csv(r'output.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}